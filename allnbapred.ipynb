{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-NBA Team Binary Classification Model\n",
    "\n",
    "Will use various classification algorithms(logisitic regression, KNN, SVM, etc) and evaluate performance on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.metrics import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze dataset\n",
    "\n",
    "Preview features (player, games started, minutes played, etc.) and training examples (the players)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>GPnS%</th>\n",
       "      <th>GPnSround%</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>61</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Adams</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>58</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>58</td>\n",
       "      <td>27.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>64</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>64</td>\n",
       "      <td>33.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>26</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>23</td>\n",
       "      <td>25.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player   G     GPnS%  GPnSround%  GS    MP   FG   FGA    FG%  \\\n",
       "0   Precious Achiuwa  61  0.055556      0.0556   4  12.1  2.0   3.7  0.544   \n",
       "1       Jaylen Adams   7  0.000000      0.0000   0   2.6  0.1   1.1  0.125   \n",
       "2       Steven Adams  58  0.805556      0.8056  58  27.7  3.3   5.3  0.614   \n",
       "3        Bam Adebayo  64  0.888889      0.8889  64  33.5  7.1  12.5  0.570   \n",
       "4  LaMarcus Aldridge  26  0.319444      0.3194  23  25.9  5.4  11.4  0.473   \n",
       "\n",
       "    3P  ...  STL  BLK  TOV   PF   PTS   PER   WS   BPM  VORP  All-NBA?  \n",
       "0  0.0  ...  0.3  0.5  0.7  1.5   5.0  14.2  1.3  -4.5  -0.5         0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.1   0.3  -6.5 -0.1 -19.8  -0.1         0  \n",
       "2  0.0  ...  0.9  0.7  1.3  1.9   7.6  15.1  4.0  -0.8   0.5         0  \n",
       "3  0.0  ...  1.2  1.0  2.6  2.3  18.7  22.7  8.8   4.7   3.6         0  \n",
       "4  1.2  ...  0.4  1.1  1.0  1.8  13.5  15.7  1.1  -0.6   0.2         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = \"DataSet.csv\"\n",
    "df = pd.read_csv(DATADIR) # read dataset\n",
    "df.head() # preview first few features and rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at list of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Player', 'G', 'GPnS%', 'GPnSround%', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
       "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'TRB', 'AST', 'STL',\n",
       "       'BLK', 'TOV', 'PF', 'PTS', 'PER', 'WS', 'BPM', 'VORP', 'All-NBA?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # list of columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove player column from dataset and store it in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = df.pop('Player') # remove Player column from dataSet and store in players\n",
    "players = np.array(players) # cast players from list into numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine players numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Precious Achiuwa', 'Jaylen Adams', 'Steven Adams', ...,\n",
       "       'Andre Drummond', 'Klay Thompson', 'Kyle Lowry'], dtype=object)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find correlation between features and target variable\n",
    "\n",
    "Use a correlation matrix to determine the features with the strongest correlation to the target variable (All-NBA?). Look at the leftmost and rightmost column to analyze strongest features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G             0.275890\n",
       "GPnS%         0.454324\n",
       "GPnSround%    0.454319\n",
       "GS            0.471530\n",
       "MP            0.402598\n",
       "FG            0.551768\n",
       "FGA           0.524672\n",
       "FG%           0.127382\n",
       "3P            0.297344\n",
       "3PA           0.297626\n",
       "3P%           0.061744\n",
       "2P            0.540380\n",
       "2PA           0.532232\n",
       "2P%           0.087835\n",
       "eFG%          0.100872\n",
       "TRB           0.418248\n",
       "AST           0.475572\n",
       "STL           0.435999\n",
       "BLK           0.274642\n",
       "TOV           0.535496\n",
       "PF            0.219371\n",
       "PTS           0.581269\n",
       "PER           0.420605\n",
       "WS            0.703642\n",
       "BPM           0.382282\n",
       "VORP          0.779935\n",
       "All-NBA?      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataSet.corr()    this prints the correlation matrix for all other features\n",
    "df.corrwith(df[\"All-NBA?\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Choose features based on strongest correlation with target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all rows and only the listed colums\n",
    "df = df.loc[:, [\"GS\", \"FG\", \"FGA\", \"2P\", \"2PA\", \"AST\", \n",
    "                \"TOV\", \"PTS\", \"WS\", \"VORP\", \"All-NBA?\"]] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Develop new features based on existing features. For example, the AST/TOV ratio is a commonly used statistic in evaluating the playmaking ability of a player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AST/TOV'] = df.apply(lambda x: x['AST'] / x['TOV'] if x['TOV'] != 0 else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.714286\n",
       "1       1.000000\n",
       "2       1.461538\n",
       "3       2.076923\n",
       "4       1.900000\n",
       "          ...   \n",
       "1110    1.242424\n",
       "1111    1.153846\n",
       "1112    0.421053\n",
       "1113    1.235294\n",
       "1114    2.206897\n",
       "Name: AST/TOV, Length: 1115, dtype: float64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AST/TOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GS          0.471530\n",
       "FG          0.551768\n",
       "FGA         0.524672\n",
       "2P          0.540380\n",
       "2PA         0.532232\n",
       "AST         0.475572\n",
       "TOV         0.535496\n",
       "PTS         0.581269\n",
       "WS          0.703642\n",
       "VORP        0.779935\n",
       "All-NBA?    1.000000\n",
       "AST/TOV     0.024009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['All-NBA?'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AST/TOV doesn't have a strong positive correlation with making an All-NBA team, so we'll discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WS</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>81</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>81</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>80</td>\n",
       "      <td>8.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>77</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GS   FG   FGA   2P   2PA  AST  TOV   PTS    WS  VORP  All-NBA?\n",
       "0      4  2.0   3.7  2.0   3.7  0.5  0.7   5.0   1.3  -0.5         0\n",
       "1      0  0.1   1.1  0.1   0.9  0.3  0.0   0.3  -0.1  -0.1         0\n",
       "2     58  3.3   5.3  3.3   5.3  1.9  1.3   7.6   4.0   0.5         0\n",
       "3     64  7.1  12.5  7.1  12.4  5.4  2.6  18.7   8.8   3.6         0\n",
       "4     23  5.4  11.4  4.2   8.3  1.9  1.0  13.5   1.1   0.2         0\n",
       "...   ..  ...   ...  ...   ...  ...  ...   ...   ...   ...       ...\n",
       "1110  81  7.5  17.9  4.9  10.9  4.1  3.3  23.1   9.2   4.9         1\n",
       "1111  74  7.2  14.1  7.2  13.9  1.5  1.3  18.0  10.1   2.5         1\n",
       "1112  81  6.8  13.1  6.8  13.0  0.8  1.9  16.2   7.4   2.0         1\n",
       "1113  80  8.1  17.3  4.7   9.2  2.1  1.7  22.1   8.0   2.5         1\n",
       "1114  77  6.6  15.6  3.9   8.5  6.4  2.9  21.2  11.6   5.0         1\n",
       "\n",
       "[1115 rows x 11 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('AST/TOV', axis = 1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scale features so that they have a uniform range. In this case we'll use Z-score normalization, which uses the following equation: $$ x_{n} = \\frac{x_{n} - \\mu_{n}}{\\sigma_{n}} $$\n",
    "where $ x_n $ is the row of the nth column, $ \\mu_{n} $ is the mean of the nth column, and $ \\sigma_{n} $ is the standard deviation of the nth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df.drop(\"All-NBA?\", axis = 1)\n",
    "\n",
    "np.save('min_init_values.npy', features_df.min().values)\n",
    "np.save('max_init_values.npy', features_df.max().values)\n",
    "\n",
    "for col in features_df:\n",
    "    df[col] = (df[col] - np.mean(df[col])) / np.std(df[col])\n",
    "len(features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('min_values.npy', df.min().values)\n",
    "np.save('max_values.npy', df.max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86927851, -1.40084893, -1.48172392, -1.22389381, -1.27587815,\n",
       "       -1.05004996, -1.28216307, -1.36106089, -1.43338617, -1.73919331,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.data[idx]     # Replace with your input feature data\n",
    "        target_sample = self.labels[idx]  # Replace with your target label data\n",
    "\n",
    "        return {'input': input_sample, 'target': target_sample}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate target variable from features and convert to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "X = df[['GS', 'FG', 'FGA', '2P', '2PA', 'AST', 'TOV', 'PTS', 'WS', 'VORP']].values  \n",
    "Y = df[['All-NBA?']].values  \n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test data split and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115 780 335\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(train_ratio * num_samples)\n",
    "test_size =  num_samples - train_size\n",
    "\n",
    "print(num_samples, train_size, test_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "X_train, Y_train = train_dataset.dataset[train_dataset.indices]\n",
    "X_test, Y_test = test_dataset.dataset[test_dataset.indices]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We'll use a sequential neural network with 2 hidden layers and a sigmoid activation function for the output layer for the binary classification. Binary Cross Entropy Loss is the used loss function, while adam is the optimizer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layers = [nn.Linear(input_size, num_neurons), nn.ReLU()]\n",
    "\n",
    "        for layer in range(1, num_layers):\n",
    "            self.layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(num_neurons, 1))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import torch.optim as optim\n",
    "\n",
    "class Estimator(BaseEstimator):\n",
    "    def __init__(self, input_size, num_layers=1, num_neurons=32, learn_rate=0.001, epochs=10):\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_neurons = num_neurons\n",
    "        self.learn_rate = learn_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        model = CustomModel(self.input_size, self.num_layers, self.num_neurons)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr = self.learn_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, X):   \n",
    "        self.model.eval()  \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            predictions = torch.where(outputs > 0.85, torch.tensor(1), torch.tensor(0))\n",
    "        return predictions\n",
    "    \n",
    "    def get_pt_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 189 candidates, totalling 567 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = param_grid = {\n",
    "    'num_layers': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'num_neurons': [64, 32, 16],\n",
    "    'learn_rate': [0.001, 0.01, 0.1],\n",
    "    'epochs': [80,90,100]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = Estimator(len(features_df.columns)),\n",
    "    param_grid = param_grid,\n",
    "    cv = 3,  # Number of cross-validation folds\n",
    "    scoring = 'f1',  # Evaluation metric\n",
    "    verbose=1,  # Verbosity level\n",
    "    error_score= 'raise'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100, 'learn_rate': 0.01, 'num_layers': 7, 'num_neurons': 64}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = best_model.get_pt_model()\n",
    "torch.save(pt_model.state_dict(), 'nbamodel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing neural network on testing dataset\n",
    "\n",
    "Evaluate performance on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.0000000e+00],\n",
      "       [3.8103742e-36],\n",
      "       [2.2334636e-17],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.5995453e-17],\n",
      "       [9.9255085e-01],\n",
      "       [0.0000000e+00],\n",
      "       [7.1544551e-30],\n",
      "       [2.6612105e-02],\n",
      "       [3.9385077e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.2233619e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.3374672e-37],\n",
      "       [0.0000000e+00],\n",
      "       [7.4011246e-24],\n",
      "       [9.9944037e-01],\n",
      "       [0.0000000e+00],\n",
      "       [3.5943595e-37],\n",
      "       [2.4042950e-18],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9709070e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.9837567e-35],\n",
      "       [0.0000000e+00],\n",
      "       [3.4331754e-16],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [5.8112421e-11],\n",
      "       [9.9684578e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.5520676e-18],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.0472887e-28],\n",
      "       [9.9987018e-01],\n",
      "       [6.0215503e-16],\n",
      "       [1.3768190e-01],\n",
      "       [1.2958293e-01]], dtype=float32), array([[0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.2244657e-07],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9430239e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.1810911e-26],\n",
      "       [0.0000000e+00],\n",
      "       [1.3298105e-18],\n",
      "       [4.3266895e-01],\n",
      "       [6.0732353e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9999321e-01],\n",
      "       [0.0000000e+00],\n",
      "       [3.7990322e-39],\n",
      "       [9.9735081e-01],\n",
      "       [1.9049205e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9793422e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.7176596e-30],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.9994006e-22],\n",
      "       [0.0000000e+00],\n",
      "       [3.6701180e-02],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.7467982e-16],\n",
      "       [8.9256825e-18],\n",
      "       [9.8540664e-01],\n",
      "       [0.0000000e+00],\n",
      "       [9.8779953e-01],\n",
      "       [9.9210888e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [5.4970210e-19],\n",
      "       [0.0000000e+00],\n",
      "       [9.9716384e-20]], dtype=float32), array([[0.00000000e+00],\n",
      "       [2.03675311e-02],\n",
      "       [3.36436255e-36],\n",
      "       [0.00000000e+00],\n",
      "       [2.46967658e-01],\n",
      "       [0.00000000e+00],\n",
      "       [1.36794828e-16],\n",
      "       [5.63865759e-20],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [6.83420634e-29],\n",
      "       [1.51420808e-18],\n",
      "       [0.00000000e+00],\n",
      "       [7.42964161e-08],\n",
      "       [1.08146045e-29],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [9.89004314e-01],\n",
      "       [0.00000000e+00],\n",
      "       [9.74392593e-01],\n",
      "       [1.40249461e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [9.85248089e-01],\n",
      "       [3.99844484e-24],\n",
      "       [2.13086102e-24],\n",
      "       [3.13953459e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [7.66343344e-24],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [6.38645699e-37],\n",
      "       [4.85112132e-27],\n",
      "       [0.00000000e+00],\n",
      "       [8.61197525e-35],\n",
      "       [0.00000000e+00],\n",
      "       [5.12299752e-22],\n",
      "       [0.00000000e+00],\n",
      "       [1.86818272e-01],\n",
      "       [7.95180968e-05],\n",
      "       [0.00000000e+00],\n",
      "       [4.11899921e-32],\n",
      "       [6.15863562e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [2.16335654e-01],\n",
      "       [1.13119140e-05],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00]], dtype=float32), array([[0.00000000e+00],\n",
      "       [1.37420538e-36],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [3.09538587e-24],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [8.13649759e-10],\n",
      "       [3.01671648e-28],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [4.64873506e-36],\n",
      "       [0.00000000e+00],\n",
      "       [5.18429959e-28],\n",
      "       [8.27936649e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [1.77301676e-28],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [5.51314932e-34],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [1.60328731e-25],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [5.13377702e-22],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [1.06641986e-32],\n",
      "       [0.00000000e+00],\n",
      "       [4.61803627e-20],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [2.38688756e-17],\n",
      "       [1.32758468e-01],\n",
      "       [0.00000000e+00],\n",
      "       [1.52183298e-35],\n",
      "       [0.00000000e+00]], dtype=float32), array([[0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.2498782e-21],\n",
      "       [0.0000000e+00],\n",
      "       [9.9934965e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.2672078e-32],\n",
      "       [0.0000000e+00],\n",
      "       [2.1117481e-31],\n",
      "       [0.0000000e+00],\n",
      "       [1.2514027e-17],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.8418715e-25],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.0110438e-21],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9976283e-01],\n",
      "       [0.0000000e+00],\n",
      "       [1.9419937e-38],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [3.8596324e-35],\n",
      "       [0.0000000e+00],\n",
      "       [3.7222933e-35],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [8.9593339e-01],\n",
      "       [0.0000000e+00],\n",
      "       [1.9385054e-14],\n",
      "       [0.0000000e+00],\n",
      "       [1.2014454e-37],\n",
      "       [0.0000000e+00],\n",
      "       [2.9340200e-02],\n",
      "       [0.0000000e+00],\n",
      "       [1.2394422e-04],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.3646754e-23],\n",
      "       [9.9999237e-01],\n",
      "       [2.7333764e-25],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.4948061e-23],\n",
      "       [2.9192438e-20],\n",
      "       [0.0000000e+00]], dtype=float32), array([[0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.0566571e-20],\n",
      "       [4.0258357e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [3.7575555e-15],\n",
      "       [0.0000000e+00],\n",
      "       [3.6829675e-37],\n",
      "       [0.0000000e+00],\n",
      "       [2.7020154e-33]], dtype=float32)]\n",
      "Test Loss: 0.0854\n",
      "Accuracy: 96.42%\n"
     ]
    }
   ],
   "source": [
    "pt_model.eval()  \n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "criterion = nn.BCELoss()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:  \n",
    "        outputs = pt_model(inputs)\n",
    "        true_labels.append(labels.cpu().numpy())\n",
    "        pred_labels.append(outputs.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted_classes = (outputs >= 0.85).float() \n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "print(pred_labels)\n",
    "true_labels = np.concatenate(true_labels)\n",
    "pred_labels = np.concatenate(pred_labels)\n",
    "\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataloader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for Performance\n",
    "\n",
    "We'll use a confusion matrix to visualize performance. In this case, the order of the confusion matrix is TP, FP, FN, TN.\n",
    "\n",
    "TP (True Positive): When prediction is 1 and the true output is 1. <br>\n",
    "FP (False Positive): When prediction is 1 and the true output is 0. <br>\n",
    "TN (True Negative): When prediction is 0 and the true output is 0. <br>\n",
    "FN (False Negative): When prediction is 0 and the true output is 1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19  10]\n",
      " [  1 305]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "threshold = 0.8\n",
    "pred_labels = (pred_labels >= threshold).astype(int)\n",
    "\n",
    "conf_mtx = confusion_matrix(true_labels, pred_labels, labels = [1,0])\n",
    "print(conf_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18fe05d6a90>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(conf_mtx)\n",
    "cm_disp.plot(cmap = \"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1 305 10\n"
     ]
    }
   ],
   "source": [
    "TP = conf_mtx[0][0]\n",
    "FP = conf_mtx[1][0]\n",
    "TN = conf_mtx[1][1]\n",
    "FN = conf_mtx[0][1]\n",
    "\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Precision is calculated as follows: $$ \\frac{TP}{(TP + FP)} $$\n",
    "\n",
    "Recall is calculated as follows: $$ \\frac{TP}{(TP + FN)} $$\n",
    "\n",
    "f1Score is calculated as follows: $$ \\frac{Precision * Recall}{(Precision + Recall)} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.95\n",
      "Recall: 0.6551724137931034\n",
      "f1score: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1score: {f1score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47e47cda05e9886a0f1932160b1f70f95aa1d71424dff224d867803480b36f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
