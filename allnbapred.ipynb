{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-NBA Team Binary Classification Model\n",
    "\n",
    "Will use various classification algorithms(logisitic regression, KNN, SVM, etc) and evaluate performance on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.metrics import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze dataset\n",
    "\n",
    "Preview features (player, games started, minutes played, etc.) and training examples (the players)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>GPnS%</th>\n",
       "      <th>GPnSround%</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>61</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Adams</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>58</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>58</td>\n",
       "      <td>27.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>64</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>64</td>\n",
       "      <td>33.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>26</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>23</td>\n",
       "      <td>25.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player   G     GPnS%  GPnSround%  GS    MP   FG   FGA    FG%  \\\n",
       "0   Precious Achiuwa  61  0.055556      0.0556   4  12.1  2.0   3.7  0.544   \n",
       "1       Jaylen Adams   7  0.000000      0.0000   0   2.6  0.1   1.1  0.125   \n",
       "2       Steven Adams  58  0.805556      0.8056  58  27.7  3.3   5.3  0.614   \n",
       "3        Bam Adebayo  64  0.888889      0.8889  64  33.5  7.1  12.5  0.570   \n",
       "4  LaMarcus Aldridge  26  0.319444      0.3194  23  25.9  5.4  11.4  0.473   \n",
       "\n",
       "    3P  ...  STL  BLK  TOV   PF   PTS   PER   WS   BPM  VORP  All-NBA?  \n",
       "0  0.0  ...  0.3  0.5  0.7  1.5   5.0  14.2  1.3  -4.5  -0.5         0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.1   0.3  -6.5 -0.1 -19.8  -0.1         0  \n",
       "2  0.0  ...  0.9  0.7  1.3  1.9   7.6  15.1  4.0  -0.8   0.5         0  \n",
       "3  0.0  ...  1.2  1.0  2.6  2.3  18.7  22.7  8.8   4.7   3.6         0  \n",
       "4  1.2  ...  0.4  1.1  1.0  1.8  13.5  15.7  1.1  -0.6   0.2         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = \"DataSet.csv\"\n",
    "df = pd.read_csv(DATADIR) # read dataset\n",
    "df.head() # preview first few features and rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at list of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Player', 'G', 'GPnS%', 'GPnSround%', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
       "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'TRB', 'AST', 'STL',\n",
       "       'BLK', 'TOV', 'PF', 'PTS', 'PER', 'WS', 'BPM', 'VORP', 'All-NBA?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # list of columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove player column from dataset and store it in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = df.pop('Player') # remove Player column from dataSet and store in players\n",
    "players = np.array(players) # cast players from list into numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine players numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Precious Achiuwa', 'Jaylen Adams', 'Steven Adams', ...,\n",
       "       'Andre Drummond', 'Klay Thompson', 'Kyle Lowry'], dtype=object)"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find correlation between features and target variable\n",
    "\n",
    "Use a correlation matrix to determine the features with the strongest correlation to the target variable (All-NBA?). Look at the leftmost and rightmost column to analyze strongest features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G             0.275890\n",
       "GPnS%         0.454324\n",
       "GPnSround%    0.454319\n",
       "GS            0.471530\n",
       "MP            0.402598\n",
       "FG            0.551768\n",
       "FGA           0.524672\n",
       "FG%           0.127382\n",
       "3P            0.297344\n",
       "3PA           0.297626\n",
       "3P%           0.061744\n",
       "2P            0.540380\n",
       "2PA           0.532232\n",
       "2P%           0.087835\n",
       "eFG%          0.100872\n",
       "TRB           0.418248\n",
       "AST           0.475572\n",
       "STL           0.435999\n",
       "BLK           0.274642\n",
       "TOV           0.535496\n",
       "PF            0.219371\n",
       "PTS           0.581269\n",
       "PER           0.420605\n",
       "WS            0.703642\n",
       "BPM           0.382282\n",
       "VORP          0.779935\n",
       "All-NBA?      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataSet.corr()    this prints the correlation matrix for all other features\n",
    "df.corrwith(df[\"All-NBA?\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Choose features based on strongest correlation with target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all rows and only the listed colums\n",
    "df = df.loc[:, [\"GS\", \"FG\", \"FGA\", \"2P\", \"2PA\", \"AST\", \n",
    "                \"TOV\", \"PTS\", \"WS\", \"VORP\", \"All-NBA?\"]] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Develop new features based on existing features. For example, the AST/TOV ratio is a commonly used statistic in evaluating the playmaking ability of a player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AST/TOV'] = df.apply(lambda x: x['AST'] / x['TOV'] if x['TOV'] != 0 else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.714286\n",
       "1       1.000000\n",
       "2       1.461538\n",
       "3       2.076923\n",
       "4       1.900000\n",
       "          ...   \n",
       "1110    1.242424\n",
       "1111    1.153846\n",
       "1112    0.421053\n",
       "1113    1.235294\n",
       "1114    2.206897\n",
       "Name: AST/TOV, Length: 1115, dtype: float64"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AST/TOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GS          0.471530\n",
       "FG          0.551768\n",
       "FGA         0.524672\n",
       "2P          0.540380\n",
       "2PA         0.532232\n",
       "AST         0.475572\n",
       "TOV         0.535496\n",
       "PTS         0.581269\n",
       "WS          0.703642\n",
       "VORP        0.779935\n",
       "All-NBA?    1.000000\n",
       "AST/TOV     0.024009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['All-NBA?'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AST/TOV doesn't have a strong positive correlation with making an All-NBA team, so we'll discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WS</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>81</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>81</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>80</td>\n",
       "      <td>8.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>77</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GS   FG   FGA   2P   2PA  AST  TOV   PTS    WS  VORP  All-NBA?\n",
       "0      4  2.0   3.7  2.0   3.7  0.5  0.7   5.0   1.3  -0.5         0\n",
       "1      0  0.1   1.1  0.1   0.9  0.3  0.0   0.3  -0.1  -0.1         0\n",
       "2     58  3.3   5.3  3.3   5.3  1.9  1.3   7.6   4.0   0.5         0\n",
       "3     64  7.1  12.5  7.1  12.4  5.4  2.6  18.7   8.8   3.6         0\n",
       "4     23  5.4  11.4  4.2   8.3  1.9  1.0  13.5   1.1   0.2         0\n",
       "...   ..  ...   ...  ...   ...  ...  ...   ...   ...   ...       ...\n",
       "1110  81  7.5  17.9  4.9  10.9  4.1  3.3  23.1   9.2   4.9         1\n",
       "1111  74  7.2  14.1  7.2  13.9  1.5  1.3  18.0  10.1   2.5         1\n",
       "1112  81  6.8  13.1  6.8  13.0  0.8  1.9  16.2   7.4   2.0         1\n",
       "1113  80  8.1  17.3  4.7   9.2  2.1  1.7  22.1   8.0   2.5         1\n",
       "1114  77  6.6  15.6  3.9   8.5  6.4  2.9  21.2  11.6   5.0         1\n",
       "\n",
       "[1115 rows x 11 columns]"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('AST/TOV', axis = 1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scale features so that they have a uniform range. In this case we'll use Z-score normalization, which uses the following equation: $$ x_{n} = \\frac{x_{n} - \\mu_{n}}{\\sigma_{n}} $$\n",
    "where $ x_n $ is the row of the nth column, $ \\mu_{n} $ is the mean of the nth column, and $ \\sigma_{n} $ is the standard deviation of the nth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df.drop(\"All-NBA?\", axis = 1)\n",
    "for col in features_df:\n",
    "    df[col] = (df[col] - np.mean(df[col])) / np.std(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WS</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.722867</td>\n",
       "      <td>-0.586508</td>\n",
       "      <td>-0.750066</td>\n",
       "      <td>-0.232221</td>\n",
       "      <td>-0.279581</td>\n",
       "      <td>-0.799192</td>\n",
       "      <td>-0.503871</td>\n",
       "      <td>-0.634993</td>\n",
       "      <td>-0.406723</td>\n",
       "      <td>-0.771077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.869279</td>\n",
       "      <td>-1.360132</td>\n",
       "      <td>-1.264204</td>\n",
       "      <td>-1.174310</td>\n",
       "      <td>-1.033536</td>\n",
       "      <td>-0.899535</td>\n",
       "      <td>-1.282163</td>\n",
       "      <td>-1.317497</td>\n",
       "      <td>-0.855888</td>\n",
       "      <td>-0.512913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.253691</td>\n",
       "      <td>-0.057186</td>\n",
       "      <td>-0.433674</td>\n",
       "      <td>0.412367</td>\n",
       "      <td>0.151250</td>\n",
       "      <td>-0.096789</td>\n",
       "      <td>0.163237</td>\n",
       "      <td>-0.257438</td>\n",
       "      <td>0.459524</td>\n",
       "      <td>-0.125667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.473309</td>\n",
       "      <td>1.490061</td>\n",
       "      <td>0.990092</td>\n",
       "      <td>2.296546</td>\n",
       "      <td>2.063063</td>\n",
       "      <td>1.659219</td>\n",
       "      <td>1.608637</td>\n",
       "      <td>1.354432</td>\n",
       "      <td>1.999518</td>\n",
       "      <td>1.875106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027411</td>\n",
       "      <td>0.797871</td>\n",
       "      <td>0.772572</td>\n",
       "      <td>0.858620</td>\n",
       "      <td>0.959058</td>\n",
       "      <td>-0.096789</td>\n",
       "      <td>-0.170317</td>\n",
       "      <td>0.599322</td>\n",
       "      <td>-0.470890</td>\n",
       "      <td>-0.319290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>2.095559</td>\n",
       "      <td>1.652929</td>\n",
       "      <td>2.057916</td>\n",
       "      <td>1.205706</td>\n",
       "      <td>1.659158</td>\n",
       "      <td>1.006988</td>\n",
       "      <td>2.386929</td>\n",
       "      <td>1.993371</td>\n",
       "      <td>2.127851</td>\n",
       "      <td>2.714139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1.839338</td>\n",
       "      <td>1.530778</td>\n",
       "      <td>1.306484</td>\n",
       "      <td>2.346130</td>\n",
       "      <td>2.466967</td>\n",
       "      <td>-0.297475</td>\n",
       "      <td>0.163237</td>\n",
       "      <td>1.252782</td>\n",
       "      <td>2.416600</td>\n",
       "      <td>1.165154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2.095559</td>\n",
       "      <td>1.367910</td>\n",
       "      <td>1.108739</td>\n",
       "      <td>2.147795</td>\n",
       "      <td>2.224624</td>\n",
       "      <td>-0.648677</td>\n",
       "      <td>0.830345</td>\n",
       "      <td>0.991398</td>\n",
       "      <td>1.550353</td>\n",
       "      <td>0.842449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2.058956</td>\n",
       "      <td>1.897232</td>\n",
       "      <td>1.939269</td>\n",
       "      <td>1.106538</td>\n",
       "      <td>1.201400</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.607975</td>\n",
       "      <td>1.848158</td>\n",
       "      <td>1.742853</td>\n",
       "      <td>1.165154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1.949147</td>\n",
       "      <td>1.286476</td>\n",
       "      <td>1.603102</td>\n",
       "      <td>0.709869</td>\n",
       "      <td>1.012912</td>\n",
       "      <td>2.160936</td>\n",
       "      <td>1.942191</td>\n",
       "      <td>1.717466</td>\n",
       "      <td>2.897848</td>\n",
       "      <td>2.778681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GS        FG       FGA        2P       2PA       AST       TOV  \\\n",
       "0    -0.722867 -0.586508 -0.750066 -0.232221 -0.279581 -0.799192 -0.503871   \n",
       "1    -0.869279 -1.360132 -1.264204 -1.174310 -1.033536 -0.899535 -1.282163   \n",
       "2     1.253691 -0.057186 -0.433674  0.412367  0.151250 -0.096789  0.163237   \n",
       "3     1.473309  1.490061  0.990092  2.296546  2.063063  1.659219  1.608637   \n",
       "4    -0.027411  0.797871  0.772572  0.858620  0.959058 -0.096789 -0.170317   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1110  2.095559  1.652929  2.057916  1.205706  1.659158  1.006988  2.386929   \n",
       "1111  1.839338  1.530778  1.306484  2.346130  2.466967 -0.297475  0.163237   \n",
       "1112  2.095559  1.367910  1.108739  2.147795  2.224624 -0.648677  0.830345   \n",
       "1113  2.058956  1.897232  1.939269  1.106538  1.201400  0.003555  0.607975   \n",
       "1114  1.949147  1.286476  1.603102  0.709869  1.012912  2.160936  1.942191   \n",
       "\n",
       "           PTS        WS      VORP  All-NBA?  \n",
       "0    -0.634993 -0.406723 -0.771077         0  \n",
       "1    -1.317497 -0.855888 -0.512913         0  \n",
       "2    -0.257438  0.459524 -0.125667         0  \n",
       "3     1.354432  1.999518  1.875106         0  \n",
       "4     0.599322 -0.470890 -0.319290         0  \n",
       "...        ...       ...       ...       ...  \n",
       "1110  1.993371  2.127851  2.714139         1  \n",
       "1111  1.252782  2.416600  1.165154         1  \n",
       "1112  0.991398  1.550353  0.842449         1  \n",
       "1113  1.848158  1.742853  1.165154         1  \n",
       "1114  1.717466  2.897848  2.778681         1  \n",
       "\n",
       "[1115 rows x 11 columns]"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.data[idx]     # Replace with your input feature data\n",
    "        target_sample = self.labels[idx]  # Replace with your target label data\n",
    "\n",
    "        return {'input': input_sample, 'target': target_sample}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate target variable from features and convert to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "X = df[['GS', 'FG', 'FGA', '2P', '2PA', 'AST', 'TOV', 'PTS', 'WS', 'VORP']].values  \n",
    "Y = df[['All-NBA?']].values  \n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test data split and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 1.0 - train_ratio\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(train_ratio * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "X_train, Y_train = train_dataset.dataset[train_dataset.indices]\n",
    "X_test, Y_test = test_dataset.dataset[test_dataset.indices]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We'll use a sequential neural network with 2 hidden layers and a sigmoid activation function for the output layer for the binary classification. Binary Cross Entropy Loss is the used loss function, while adam is the optimizer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(features_df.columns), 32),\n",
    "    nn.ReLU(),  \n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(16, 1),\n",
    "    nn.Sigmoid(),  \n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network\n",
    "\n",
    "Perform forward propagation and back propagation when training neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.5955\n",
      "Epoch [2/100], Training Loss: 0.5283\n",
      "Epoch [3/100], Training Loss: 0.4519\n",
      "Epoch [4/100], Training Loss: 0.3743\n",
      "Epoch [5/100], Training Loss: 0.2976\n",
      "Epoch [6/100], Training Loss: 0.2400\n",
      "Epoch [7/100], Training Loss: 0.1994\n",
      "Epoch [8/100], Training Loss: 0.1677\n",
      "Epoch [9/100], Training Loss: 0.1447\n",
      "Epoch [10/100], Training Loss: 0.1247\n",
      "Epoch [11/100], Training Loss: 0.1210\n",
      "Epoch [12/100], Training Loss: 0.1146\n",
      "Epoch [13/100], Training Loss: 0.0923\n",
      "Epoch [14/100], Training Loss: 0.0808\n",
      "Epoch [15/100], Training Loss: 0.0729\n",
      "Epoch [16/100], Training Loss: 0.0721\n",
      "Epoch [17/100], Training Loss: 0.0671\n",
      "Epoch [18/100], Training Loss: 0.0653\n",
      "Epoch [19/100], Training Loss: 0.0579\n",
      "Epoch [20/100], Training Loss: 0.0548\n",
      "Epoch [21/100], Training Loss: 0.0534\n",
      "Epoch [22/100], Training Loss: 0.0511\n",
      "Epoch [23/100], Training Loss: 0.0532\n",
      "Epoch [24/100], Training Loss: 0.0531\n",
      "Epoch [25/100], Training Loss: 0.0468\n",
      "Epoch [26/100], Training Loss: 0.0465\n",
      "Epoch [27/100], Training Loss: 0.0535\n",
      "Epoch [28/100], Training Loss: 0.0483\n",
      "Epoch [29/100], Training Loss: 0.0555\n",
      "Epoch [30/100], Training Loss: 0.0458\n",
      "Epoch [31/100], Training Loss: 0.0556\n",
      "Epoch [32/100], Training Loss: 0.0474\n",
      "Epoch [33/100], Training Loss: 0.0427\n",
      "Epoch [34/100], Training Loss: 0.0424\n",
      "Epoch [35/100], Training Loss: 0.0417\n",
      "Epoch [36/100], Training Loss: 0.0427\n",
      "Epoch [37/100], Training Loss: 0.0408\n",
      "Epoch [38/100], Training Loss: 0.0403\n",
      "Epoch [39/100], Training Loss: 0.0509\n",
      "Epoch [40/100], Training Loss: 0.0435\n",
      "Epoch [41/100], Training Loss: 0.0392\n",
      "Epoch [42/100], Training Loss: 0.0417\n",
      "Epoch [43/100], Training Loss: 0.0402\n",
      "Epoch [44/100], Training Loss: 0.0392\n",
      "Epoch [45/100], Training Loss: 0.0425\n",
      "Epoch [46/100], Training Loss: 0.0464\n",
      "Epoch [47/100], Training Loss: 0.0401\n",
      "Epoch [48/100], Training Loss: 0.0389\n",
      "Epoch [49/100], Training Loss: 0.0431\n",
      "Epoch [50/100], Training Loss: 0.0389\n",
      "Epoch [51/100], Training Loss: 0.0393\n",
      "Epoch [52/100], Training Loss: 0.0392\n",
      "Epoch [53/100], Training Loss: 0.0372\n",
      "Epoch [54/100], Training Loss: 0.0374\n",
      "Epoch [55/100], Training Loss: 0.0373\n",
      "Epoch [56/100], Training Loss: 0.0370\n",
      "Epoch [57/100], Training Loss: 0.0365\n",
      "Epoch [58/100], Training Loss: 0.0361\n",
      "Epoch [59/100], Training Loss: 0.0367\n",
      "Epoch [60/100], Training Loss: 0.0368\n",
      "Epoch [61/100], Training Loss: 0.0356\n",
      "Epoch [62/100], Training Loss: 0.0424\n",
      "Epoch [63/100], Training Loss: 0.0363\n",
      "Epoch [64/100], Training Loss: 0.0361\n",
      "Epoch [65/100], Training Loss: 0.0351\n",
      "Epoch [66/100], Training Loss: 0.0459\n",
      "Epoch [67/100], Training Loss: 0.0439\n",
      "Epoch [68/100], Training Loss: 0.0386\n",
      "Epoch [69/100], Training Loss: 0.0372\n",
      "Epoch [70/100], Training Loss: 0.0343\n",
      "Epoch [71/100], Training Loss: 0.0345\n",
      "Epoch [72/100], Training Loss: 0.0346\n",
      "Epoch [73/100], Training Loss: 0.0423\n",
      "Epoch [74/100], Training Loss: 0.0382\n",
      "Epoch [75/100], Training Loss: 0.0349\n",
      "Epoch [76/100], Training Loss: 0.0347\n",
      "Epoch [77/100], Training Loss: 0.0339\n",
      "Epoch [78/100], Training Loss: 0.0357\n",
      "Epoch [79/100], Training Loss: 0.0362\n",
      "Epoch [80/100], Training Loss: 0.0345\n",
      "Epoch [81/100], Training Loss: 0.0344\n",
      "Epoch [82/100], Training Loss: 0.0335\n",
      "Epoch [83/100], Training Loss: 0.0405\n",
      "Epoch [84/100], Training Loss: 0.0372\n",
      "Epoch [85/100], Training Loss: 0.0423\n",
      "Epoch [86/100], Training Loss: 0.0337\n",
      "Epoch [87/100], Training Loss: 0.0356\n",
      "Epoch [88/100], Training Loss: 0.0329\n",
      "Epoch [89/100], Training Loss: 0.0523\n",
      "Epoch [90/100], Training Loss: 0.0367\n",
      "Epoch [91/100], Training Loss: 0.0333\n",
      "Epoch [92/100], Training Loss: 0.0327\n",
      "Epoch [93/100], Training Loss: 0.0342\n",
      "Epoch [94/100], Training Loss: 0.0318\n",
      "Epoch [95/100], Training Loss: 0.0315\n",
      "Epoch [96/100], Training Loss: 0.0369\n",
      "Epoch [97/100], Training Loss: 0.0328\n",
      "Epoch [98/100], Training Loss: 0.0353\n",
      "Epoch [99/100], Training Loss: 0.0324\n",
      "Epoch [100/100], Training Loss: 0.0394\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_dataloader:  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_loss:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing neural network on testing dataset\n",
    "\n",
    "Evaluate performance on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0520\n",
      "Accuracy: 97.01%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:  \n",
    "        outputs = model(inputs)\n",
    "        true_labels.append(labels.cpu().numpy())\n",
    "        pred_labels.append(outputs.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted_classes = (outputs >= 0.7).float()  \n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "true_labels = np.concatenate(true_labels)\n",
    "pred_labels = np.concatenate(pred_labels)\n",
    "\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataloader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for Performance\n",
    "\n",
    "We'll use a confusion matrix to visualize performance. In this case, the order of the confusion matrix is TP, FP, FN, TN.\n",
    "\n",
    "TP (True Positive): When prediction is 1 and the true output is 1. <br>\n",
    "FP (False Positive): When prediction is 1 and the true output is 0. <br>\n",
    "TN (True Negative): When prediction is 0 and the true output is 0. <br>\n",
    "FN (False Negative): When prediction is 0 and the true output is 1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23   9]\n",
      " [  1 302]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "threshold = 0.7\n",
    "\n",
    "pred_labels = (pred_labels >= threshold).astype(int)\n",
    "\n",
    "conf_mtx = confusion_matrix(true_labels, pred_labels, labels = [1,0])\n",
    "print(conf_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "plt.xlabel(\"\")\n",
    "sns.heatmap(conf_mtx, annot = True, cmap = \"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 1 302 9\n"
     ]
    }
   ],
   "source": [
    "TP = conf_mtx[0][0]\n",
    "FP = conf_mtx[1][0]\n",
    "TN = conf_mtx[1][1]\n",
    "FN = conf_mtx[0][1]\n",
    "\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Precision is calculated as follows: $$ \\frac{TP}{(TP + FP)} $$\n",
    "\n",
    "Recall is calculated as follows: $$ \\frac{TP}{(TP + FN)} $$\n",
    "\n",
    "f1Score is calculated as follows: $$ \\frac{Precision * Recall}{(Precision + Recall)} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9583333333333334\n",
      "Recall: 0.71875\n",
      "f1score: 0.4107142857142857\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1score = (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1score: {f1score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47e47cda05e9886a0f1932160b1f70f95aa1d71424dff224d867803480b36f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
