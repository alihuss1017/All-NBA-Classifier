{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-NBA Team Binary Classification Model\n",
    "\n",
    "Will use various classification algorithms(logisitic regression, KNN, SVM, etc) and evaluate performance on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.metrics import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze dataset\n",
    "\n",
    "Preview features (player, games started, minutes played, etc.) and training examples (the players)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>GPnS%</th>\n",
       "      <th>GPnSround%</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>61</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Adams</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>58</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>58</td>\n",
       "      <td>27.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>64</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>64</td>\n",
       "      <td>33.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>26</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>23</td>\n",
       "      <td>25.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player   G     GPnS%  GPnSround%  GS    MP   FG   FGA    FG%  \\\n",
       "0   Precious Achiuwa  61  0.055556      0.0556   4  12.1  2.0   3.7  0.544   \n",
       "1       Jaylen Adams   7  0.000000      0.0000   0   2.6  0.1   1.1  0.125   \n",
       "2       Steven Adams  58  0.805556      0.8056  58  27.7  3.3   5.3  0.614   \n",
       "3        Bam Adebayo  64  0.888889      0.8889  64  33.5  7.1  12.5  0.570   \n",
       "4  LaMarcus Aldridge  26  0.319444      0.3194  23  25.9  5.4  11.4  0.473   \n",
       "\n",
       "    3P  ...  STL  BLK  TOV   PF   PTS   PER   WS   BPM  VORP  All-NBA?  \n",
       "0  0.0  ...  0.3  0.5  0.7  1.5   5.0  14.2  1.3  -4.5  -0.5         0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.1   0.3  -6.5 -0.1 -19.8  -0.1         0  \n",
       "2  0.0  ...  0.9  0.7  1.3  1.9   7.6  15.1  4.0  -0.8   0.5         0  \n",
       "3  0.0  ...  1.2  1.0  2.6  2.3  18.7  22.7  8.8   4.7   3.6         0  \n",
       "4  1.2  ...  0.4  1.1  1.0  1.8  13.5  15.7  1.1  -0.6   0.2         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = \"../Data/DataSet.csv\"\n",
    "df = pd.read_csv(DATADIR) # read dataset\n",
    "df.head() # preview first few features and rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at list of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Player', 'G', 'GPnS%', 'GPnSround%', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
       "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'TRB', 'AST', 'STL',\n",
       "       'BLK', 'TOV', 'PF', 'PTS', 'PER', 'WS', 'BPM', 'VORP', 'All-NBA?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # list of columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove player column from dataset and store it in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = df.pop('Player') # remove Player column from dataSet and store in players\n",
    "players = np.array(players) # cast players from list into numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine players numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Precious Achiuwa', 'Jaylen Adams', 'Steven Adams', ...,\n",
       "       'Andre Drummond', 'Klay Thompson', 'Kyle Lowry'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find correlation between features and target variable\n",
    "\n",
    "Use a correlation matrix to determine the features with the strongest correlation to the target variable (All-NBA?). Look at the leftmost and rightmost column to analyze strongest features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G             0.275890\n",
       "GPnS%         0.454324\n",
       "GPnSround%    0.454319\n",
       "GS            0.471530\n",
       "MP            0.402598\n",
       "FG            0.551768\n",
       "FGA           0.524672\n",
       "FG%           0.127382\n",
       "3P            0.297344\n",
       "3PA           0.297626\n",
       "3P%           0.061744\n",
       "2P            0.540380\n",
       "2PA           0.532232\n",
       "2P%           0.087835\n",
       "eFG%          0.100872\n",
       "TRB           0.418248\n",
       "AST           0.475572\n",
       "STL           0.435999\n",
       "BLK           0.274642\n",
       "TOV           0.535496\n",
       "PF            0.219371\n",
       "PTS           0.581269\n",
       "PER           0.420605\n",
       "WS            0.703642\n",
       "BPM           0.382282\n",
       "VORP          0.779935\n",
       "All-NBA?      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataSet.corr()    this prints the correlation matrix for all other features\n",
    "df.corrwith(df[\"All-NBA?\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Choose features based on strongest correlation with target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all rows and only the listed colums\n",
    "df = df.loc[:, [\"GS\", \"FG\", \"FGA\", \"2P\", \"2PA\", \"AST\", \n",
    "                \"TOV\", \"PTS\", \"WS\", \"VORP\", \"All-NBA?\"]] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Develop new features based on existing features. For example, the AST/TOV ratio is a commonly used statistic in evaluating the playmaking ability of a player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AST/TOV'] = df.apply(lambda x: x['AST'] / x['TOV'] if x['TOV'] != 0 else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.714286\n",
       "1       1.000000\n",
       "2       1.461538\n",
       "3       2.076923\n",
       "4       1.900000\n",
       "          ...   \n",
       "1110    1.242424\n",
       "1111    1.153846\n",
       "1112    0.421053\n",
       "1113    1.235294\n",
       "1114    2.206897\n",
       "Name: AST/TOV, Length: 1115, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AST/TOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GS          0.471530\n",
       "FG          0.551768\n",
       "FGA         0.524672\n",
       "2P          0.540380\n",
       "2PA         0.532232\n",
       "AST         0.475572\n",
       "TOV         0.535496\n",
       "PTS         0.581269\n",
       "WS          0.703642\n",
       "VORP        0.779935\n",
       "All-NBA?    1.000000\n",
       "AST/TOV     0.024009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['All-NBA?'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AST/TOV doesn't have a strong positive correlation with making an All-NBA team, so we'll discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WS</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>81</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>81</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>80</td>\n",
       "      <td>8.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>77</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GS   FG   FGA   2P   2PA  AST  TOV   PTS    WS  VORP  All-NBA?\n",
       "0      4  2.0   3.7  2.0   3.7  0.5  0.7   5.0   1.3  -0.5         0\n",
       "1      0  0.1   1.1  0.1   0.9  0.3  0.0   0.3  -0.1  -0.1         0\n",
       "2     58  3.3   5.3  3.3   5.3  1.9  1.3   7.6   4.0   0.5         0\n",
       "3     64  7.1  12.5  7.1  12.4  5.4  2.6  18.7   8.8   3.6         0\n",
       "4     23  5.4  11.4  4.2   8.3  1.9  1.0  13.5   1.1   0.2         0\n",
       "...   ..  ...   ...  ...   ...  ...  ...   ...   ...   ...       ...\n",
       "1110  81  7.5  17.9  4.9  10.9  4.1  3.3  23.1   9.2   4.9         1\n",
       "1111  74  7.2  14.1  7.2  13.9  1.5  1.3  18.0  10.1   2.5         1\n",
       "1112  81  6.8  13.1  6.8  13.0  0.8  1.9  16.2   7.4   2.0         1\n",
       "1113  80  8.1  17.3  4.7   9.2  2.1  1.7  22.1   8.0   2.5         1\n",
       "1114  77  6.6  15.6  3.9   8.5  6.4  2.9  21.2  11.6   5.0         1\n",
       "\n",
       "[1115 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('AST/TOV', axis = 1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scale features so that they have a uniform range. In this case we'll use Z-score normalization, which uses the following equation: $$ x_{n} = \\frac{x_{n} - \\mu_{n}}{\\sigma_{n}} $$\n",
    "where $ x_n $ is the row of the nth column, $ \\mu_{n} $ is the mean of the nth column, and $ \\sigma_{n} $ is the standard deviation of the nth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df.drop(\"All-NBA?\", axis = 1)\n",
    "\n",
    "np.save('../Data/min_init_values.npy', features_df.min().values)\n",
    "np.save('../Data/max_init_values.npy', features_df.max().values)\n",
    "\n",
    "for col in features_df:\n",
    "    df[col] = (df[col] - np.mean(df[col])) / np.std(df[col])\n",
    "len(features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Data/min_values.npy', df.min().values)\n",
    "np.save('../Data/max_values.npy', df.max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86927851, -1.40084893, -1.48172392, -1.22389381, -1.27587815,\n",
       "       -1.05004996, -1.28216307, -1.36106089, -1.43338617, -1.73919331,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.data[idx]     # Replace with your input feature data\n",
    "        target_sample = self.labels[idx]  # Replace with your target label data\n",
    "\n",
    "        return {'input': input_sample, 'target': target_sample}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate target variable from features and convert to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "X = df[['GS', 'FG', 'FGA', '2P', '2PA', 'AST', 'TOV', 'PTS', 'WS', 'VORP']].values  \n",
    "Y = df[['All-NBA?']].values  \n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test data split and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115 780 335\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(train_ratio * num_samples)\n",
    "test_size =  num_samples - train_size\n",
    "\n",
    "print(num_samples, train_size, test_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "X_train, Y_train = train_dataset.dataset[train_dataset.indices]\n",
    "X_test, Y_test = test_dataset.dataset[test_dataset.indices]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We'll use a sequential neural network with 2 hidden layers and a sigmoid activation function for the output layer for the binary classification. Binary Cross Entropy Loss is the used loss function, while adam is the optimizer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layers = [nn.Linear(input_size, num_neurons), nn.ReLU()]\n",
    "\n",
    "        for layer in range(1, num_layers):\n",
    "            self.layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers.append(nn.Linear(num_neurons, 1))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import torch.optim as optim\n",
    "\n",
    "class Estimator(BaseEstimator):\n",
    "    def __init__(self, input_size, num_layers=1, num_neurons=32, learn_rate=0.001, epochs=10):\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_neurons = num_neurons\n",
    "        self.learn_rate = learn_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        model = CustomModel(self.input_size, self.num_layers, self.num_neurons)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr = self.learn_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, X):   \n",
    "        self.model.eval()  \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            predictions = torch.where(outputs > 0.85, torch.tensor(1), torch.tensor(0))\n",
    "        return predictions\n",
    "    \n",
    "    def get_pt_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 189 candidates, totalling 567 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = param_grid = {\n",
    "    'num_layers': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'num_neurons': [64, 32, 16],\n",
    "    'learn_rate': [0.001, 0.01, 0.1],\n",
    "    'epochs': [80,90,100]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = Estimator(len(features_df.columns)),\n",
    "    param_grid = param_grid,\n",
    "    cv = 3,  # Number of cross-validation folds\n",
    "    scoring = 'f1',  # Evaluation metric\n",
    "    verbose=1,  # Verbosity level\n",
    "    error_score= 'raise'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 100, 'learn_rate': 0.01, 'num_layers': 4, 'num_neurons': 64}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = best_model.get_pt_model()\n",
    "torch.save(pt_model.state_dict(), '../Models/nbamodel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing neural network on testing dataset\n",
    "\n",
    "Evaluate performance on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.00000000e+00],\n",
      "       [2.63136613e-14],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [9.99894977e-01],\n",
      "       [2.95230786e-17],\n",
      "       [0.00000000e+00],\n",
      "       [4.79373611e-38],\n",
      "       [5.27683005e-06],\n",
      "       [7.99087435e-02],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [9.99797523e-01],\n",
      "       [0.00000000e+00],\n",
      "       [9.99534130e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [3.22620687e-14],\n",
      "       [1.18643385e-11],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [5.71517482e-17],\n",
      "       [0.00000000e+00],\n",
      "       [9.99999762e-01],\n",
      "       [0.00000000e+00],\n",
      "       [9.99832511e-01],\n",
      "       [0.00000000e+00],\n",
      "       [2.80674563e-20],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [4.57569959e-30],\n",
      "       [0.00000000e+00],\n",
      "       [4.49804544e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [1.83097607e-18],\n",
      "       [6.39261158e-33],\n",
      "       [1.51080061e-02],\n",
      "       [9.99425530e-01],\n",
      "       [0.00000000e+00],\n",
      "       [1.78960168e-15],\n",
      "       [0.00000000e+00],\n",
      "       [7.30952608e-21],\n",
      "       [0.00000000e+00],\n",
      "       [8.75580299e-04],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [9.99972105e-01],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00],\n",
      "       [4.89425461e-23],\n",
      "       [0.00000000e+00],\n",
      "       [0.00000000e+00]], dtype=float32), array([[0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.0097221e-08],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.9364954e-04],\n",
      "       [1.3113525e-02],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9998188e-01],\n",
      "       [1.1473372e-37],\n",
      "       [9.9987328e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.3173045e-30],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.0063588e-25],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.1181863e-16],\n",
      "       [9.0111981e-36],\n",
      "       [9.9149454e-01],\n",
      "       [9.7649211e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [8.2647997e-01],\n",
      "       [0.0000000e+00],\n",
      "       [1.7149818e-29],\n",
      "       [5.6282679e-31],\n",
      "       [9.4693265e-16],\n",
      "       [0.0000000e+00],\n",
      "       [1.8283114e-09],\n",
      "       [0.0000000e+00],\n",
      "       [1.5026449e-37],\n",
      "       [0.0000000e+00],\n",
      "       [9.9953628e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.1451383e-36],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.5663728e-23],\n",
      "       [5.9058219e-10],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00]], dtype=float32), array([[0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.4334994e-33],\n",
      "       [5.8061426e-27],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.2508680e-10],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.6673818e-01],\n",
      "       [9.9999785e-01],\n",
      "       [1.9084131e-20],\n",
      "       [2.3419524e-18],\n",
      "       [9.9999344e-01],\n",
      "       [8.1332323e-23],\n",
      "       [0.0000000e+00],\n",
      "       [9.9999964e-01],\n",
      "       [9.4988193e-22],\n",
      "       [0.0000000e+00],\n",
      "       [1.4059397e-15],\n",
      "       [0.0000000e+00],\n",
      "       [3.0174223e-04],\n",
      "       [1.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.7264190e-02],\n",
      "       [1.2086306e-29],\n",
      "       [1.5862820e-04],\n",
      "       [9.9978858e-01],\n",
      "       [1.8070141e-13],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.0353163e-34],\n",
      "       [0.0000000e+00],\n",
      "       [1.5357732e-10],\n",
      "       [0.0000000e+00],\n",
      "       [7.2529437e-22],\n",
      "       [1.4358807e-07],\n",
      "       [1.6893318e-07],\n",
      "       [1.7605379e-32],\n",
      "       [5.6189764e-17],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.4545647e-31],\n",
      "       [6.2132327e-11],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [3.1370681e-28],\n",
      "       [1.2964864e-32],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9994755e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00]], dtype=float32), array([[2.3356411e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9749124e-01],\n",
      "       [9.9991870e-01],\n",
      "       [9.9672216e-01],\n",
      "       [0.0000000e+00],\n",
      "       [3.5240657e-18],\n",
      "       [0.0000000e+00],\n",
      "       [4.2217421e-20],\n",
      "       [7.1677150e-27],\n",
      "       [7.0474961e-20],\n",
      "       [1.2068071e-20],\n",
      "       [6.4043480e-27],\n",
      "       [5.5203642e-09],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.3983116e-12],\n",
      "       [8.7486151e-23],\n",
      "       [5.8497704e-24],\n",
      "       [0.0000000e+00],\n",
      "       [8.8454401e-03],\n",
      "       [0.0000000e+00],\n",
      "       [1.7717128e-27],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9620146e-01],\n",
      "       [0.0000000e+00],\n",
      "       [4.4820952e-39],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [3.0759030e-18],\n",
      "       [7.9147316e-22],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.6369346e-09],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.5386391e-27],\n",
      "       [7.4514233e-02],\n",
      "       [6.2913373e-20],\n",
      "       [2.4347699e-03],\n",
      "       [0.0000000e+00],\n",
      "       [6.4589304e-01],\n",
      "       [0.0000000e+00],\n",
      "       [3.5991653e-20],\n",
      "       [0.0000000e+00],\n",
      "       [9.9995041e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.0178035e-02],\n",
      "       [1.4756861e-04],\n",
      "       [1.6280310e-34],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [7.5461504e-16],\n",
      "       [0.0000000e+00],\n",
      "       [4.0046451e-15]], dtype=float32), array([[2.0763667e-11],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.0583150e-24],\n",
      "       [0.0000000e+00],\n",
      "       [2.7177525e-03],\n",
      "       [0.0000000e+00],\n",
      "       [4.0547387e-24],\n",
      "       [1.0110392e-15],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.1456822e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [2.6276467e-20],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.7632196e-14],\n",
      "       [0.0000000e+00],\n",
      "       [1.0000000e+00],\n",
      "       [3.7557462e-32],\n",
      "       [0.0000000e+00],\n",
      "       [9.4603384e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.7403062e-21],\n",
      "       [9.9997842e-01],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.4800199e-17],\n",
      "       [4.3958393e-17],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [6.1720041e-13],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.9871745e-21],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [9.9846727e-01]], dtype=float32), array([[0.0000000e+00],\n",
      "       [1.8149203e-06],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [1.8153645e-31],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [0.0000000e+00],\n",
      "       [4.1166168e-05],\n",
      "       [8.4294680e-21],\n",
      "       [9.0179333e-07],\n",
      "       [0.0000000e+00]], dtype=float32)]\n",
      "Test Loss: 0.1287\n",
      "Accuracy: 97.91%\n"
     ]
    }
   ],
   "source": [
    "pt_model.eval()  \n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "criterion = nn.BCELoss()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:  \n",
    "        outputs = pt_model(inputs)\n",
    "        true_labels.append(labels.cpu().numpy())\n",
    "        pred_labels.append(outputs.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted_classes = (outputs >= 0.85).float() \n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "print(pred_labels)\n",
    "true_labels = np.concatenate(true_labels)\n",
    "pred_labels = np.concatenate(pred_labels)\n",
    "\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataloader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for Performance\n",
    "\n",
    "We'll use a confusion matrix to visualize performance. In this case, the order of the confusion matrix is TP, FP, FN, TN.\n",
    "\n",
    "TP (True Positive): When prediction is 1 and the true output is 1. <br>\n",
    "FP (False Positive): When prediction is 1 and the true output is 0. <br>\n",
    "TN (True Negative): When prediction is 0 and the true output is 0. <br>\n",
    "FN (False Negative): When prediction is 0 and the true output is 1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24   4]\n",
      " [  4 303]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "threshold = 0.8\n",
    "pred_labels = (pred_labels >= threshold).astype(int)\n",
    "\n",
    "conf_mtx = confusion_matrix(true_labels, pred_labels, labels = [1,0])\n",
    "print(conf_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2603f0dd350>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGyCAYAAADj3G12AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0GklEQVR4nO3df1hUZf7/8dcMyg+RGSMFJNE0UyR/lbXIVqZloralq21ra0Vm9tHEStLU3fxZSWvtWpZpv9G+uvZTW6lsTRM1SZOkrJQNs0UT0DJBKAHhfP8wZnfScoaZYZw5z0fXfV3OOfc55z1dXr7nfd/3OcdiGIYhAAAQtKz+DgAAAPgWyR4AgCBHsgcAIMiR7AEACHIkewAAghzJHgCAIEeyBwAgyJHsAQAIciR7AACCXBN/B+CJuro6HThwQFFRUbJYLP4OBwDgJsMwdPToUcXHx8tq9V39eezYMVVXV3t8ntDQUIWHh3shokZmBLB9+/YZkmg0Go0W4G3fvn0+yxU//vij0UwWr8QZFxdn/Pjjjy5d96mnnjK6detmREVFGVFRUUbv3r2Nt99+2ymuO++804iOjjYiIyONYcOGGSUlJU7n+M9//mMMHjzYiIiIMFq1amVMmjTJqKmpcfv/QUBX9lFRUZKkoh25skU193M0gG9YIu3+DgHwmfKjR5XQ6QLHv+e+UF1drR9kaKQiFaqGjwJXy9CykhJVV1e7VN23adNGDz/8sM4//3wZhqElS5ZoyJAh2rFjhy644AJNnDhRb731ll599VXZ7Xalp6dr2LBh+uCDDyRJtbW1uuaaaxQXF6ctW7aouLhYt9xyi5o2baq5c+e6FbvFMAL3RTjl5eWy2+06UrhTNh/+RQH8ydK8hb9DAHymvLxc9tZtVVZWJpvN5rtr2O0areYeJ/vnVeFRrNHR0XrkkUd0/fXXq1WrVlq+fLmuv/56SdLu3bvVpUsX5ebmqnfv3nrnnXf0u9/9TgcOHFBsbKwkafHixZoyZYoOHTqk0NBQl6/LAj0AgClYZZHV4kH76YdCeXm5U6uqqjrttWtra7VixQpVVlYqJSVFeXl5qqmpUf/+/R19EhMT1bZtW+Xm5kqScnNz1a1bN0eil6TU1FSVl5fr888/d/O7AwBgAlYvNElKSEiQ3W53tMzMzF+85s6dO9W8eXOFhYVp7NixWrlypZKSklRSUqLQ0FC1aNHCqX9sbKxKSkokSSUlJU6Jvn5//T53BPScPQAAjW3fvn1Ow/hhYWG/2Ldz587Kz89XWVmZXnvtNaWlpSknJ6cxwnRCsgcAmILFIlk9uEvbIkmGZLPZXJ6zDw0NVceOHSVJvXr10kcffaTHH39cf/zjH1VdXa0jR444VfelpaWKi4uTJMXFxWnbtm1O5ystLXXscwfD+AAAU/DWML4n6urqVFVVpV69eqlp06Zat26dY19BQYGKioqUkpIiSUpJSdHOnTt18OBBR5+1a9fKZrMpKSnJretS2QMA4APTpk3ToEGD1LZtWx09elTLly/Xhg0b9O677564O2D0aGVkZCg6Olo2m00TJkxQSkqKevfuLUkaMGCAkpKSdPPNN2vevHkqKSnR/fffr/Hjx//q1MGpkOwBAKZQv6q+wcdLJx6t46KDBw/qlltuUXFxsex2u7p37653331XV199tSRp/vz5slqtGj58uKqqqpSamqqnnnrKcXxISIiys7M1btw4paSkKDIyUmlpaZozZ47bsXOfPXCG4z57BLPGvM/+LqtNYR4k+yrD0IK6cp/G6ivM2QMAEOQYxgcAmILVw9X4gVwdk+wBAKbg6Yr6QE72gRw7AABwAZU9AMAULBaLLB4s0PNgBsDvSPYAAFMw8zA+yR4AYApmXqAXyLEDAAAXUNkDAEzBIs8qXObsAQA4w3nlcbkBKpBjBwAALqCyBwCYAqvxAQAIcqzGBwAAQYvKHgBgCgzjAwAQ5KyyyOrBDXSBnOwDOXYAAOACKnsAgCmYeYEeyR4AYArM2QMAEOTMXNkHcuwAAMAFVPYAAFM48SKchpf2FhneC6aRkewBAKbAMD4AAAhaVPYAAFNgNT4AAEGOYXwAABC0qOwBAKbg+bPxPRgW8DOSPQDAFBjGBwAAQYvKHgBgCpafmifHByqSPQDAFMw8jE+yBwCYgpkX6AXyDxUAAOACKnsAgCkwjA8AQJA78dY7z44PVIH8QwUAALiAyh4AYArcegcAQJCzWiyyWliNDwAAghCVPQDAFBjGBwAgyJk52TOMDwBAkKOyBwCYgpkre5I9AMAULBaLLB6sxrcEcLon2QMATMHMlT1z9gAABDkqewCAKVjlWYUbyNUxyR4AYAoWy4nW4OO9F0qjC+QfKgAAwAVU9gAAU7D89J8nxwcqKnsAgClYvNDckZmZqUsuuURRUVGKiYnR0KFDVVBQ4NSnb9++jlsC69vYsWOd+hQVFemaa65Rs2bNFBMTo8mTJ+v48eNuxUJlDwCAD+Tk5Gj8+PG65JJLdPz4cf35z3/WgAED9MUXXygyMtLRb8yYMZozZ47jc7NmzRx/rq2t1TXXXKO4uDht2bJFxcXFuuWWW9S0aVPNnTvX5VhI9gAAU2js++zXrFnj9DkrK0sxMTHKy8tTnz59HNubNWumuLi4U57jX//6l7744gu99957io2NVc+ePfXAAw9oypQpmjVrlkJDQ12KhWF8AIApWCVZLR60n85TXl7u1Kqqqly6fllZmSQpOjraafuyZcvUsmVLde3aVdOmTdMPP/zg2Jebm6tu3bopNjbWsS01NVXl5eX6/PPPXf7uVPYAALghISHB6fPMmTM1a9asXz2mrq5O99xzjy699FJ17drVsf1Pf/qT2rVrp/j4eH366aeaMmWKCgoK9MYbb0iSSkpKnBK9JMfnkpISl2Mm2QMATMFbq/H37dsnm83m2B4WFnbaY8ePH6/PPvtMmzdvdtp+xx13OP7crVs3tW7dWldddZX27Nmj8847r8Gx/hzD+AAA0/DGSnybzebUTpfs09PTlZ2drffff19t2rT51b7JycmSpMLCQklSXFycSktLnfrUf/6lef5TIdkDAEyh/gl6njR3GIah9PR0rVy5UuvXr1f79u1Pe0x+fr4kqXXr1pKklJQU7dy5UwcPHnT0Wbt2rWw2m5KSklyOhWF8AAB8YPz48Vq+fLnefPNNRUVFOebY7Xa7IiIitGfPHi1fvlyDBw/W2WefrU8//VQTJ05Unz591L17d0nSgAEDlJSUpJtvvlnz5s1TSUmJ7r//fo0fP96l6YN6VPYAAFNo7IfqLFq0SGVlZerbt69at27taC+//LIkKTQ0VO+9954GDBigxMRE3XvvvRo+fLhWr17tOEdISIiys7MVEhKilJQU3XTTTbrllluc7st3BZU9AMAUrLLI6sECPXePNQzjV/cnJCQoJyfntOdp166d3n77bbeu/XNU9gAABDkqewCAKTT2E/TOJCR7AIApePw++wDO9gzjAwAQ5KjsAQCmwDA+AABBzluPyw1EDOMDABDkqOwBAKZQ/6paT44PVCR7AIApMGcPAECQM3OyZ84eAIAgR2UPADAFM6/GJ9kDAEyBJ+gBAICgRbLHSdY8/pweTh2hezoka3LSFVqcdpdKCveesq9hGHrixrEaF9tN+W+va+RIAd9Y8+hCjY1M0CuTZ/k7FHiR1QstUAVy7PCRL3O364pRI3Tf28t096vPqPb4cT3xx/9TVeUPJ/Vd//RLsgTy2BbwM1/n5WvTC8t0Ttcu/g4FXmbxQgtUZ0SyX7hwoc4991yFh4crOTlZ27Zt83dIpjZhxWKljBiq+MSOanNBZ93y+IM6vL9YRZ9+4dRv32e79d7iJbr5sQf8FCngXccqKvXCbXfppif/qmZn2f0dDuA1fk/2L7/8sjIyMjRz5kx9/PHH6tGjh1JTU3Xw4EF/h4af/Hi0QpLUrMV///Gr/uFHvTBuikZk/kX2mJb+Cg3wqhUT71fX1CvV5crL/R0KfMFikcWDFsgr9Pye7P/+979rzJgxGjVqlJKSkrR48WI1a9ZML7zwgr9Dg6S6ujq9ev9fdd5vLtQ5Xc53bH91xjx1uLinegy60o/RAd7z0atvqih/p34/Z6q/Q4GPmHkY36+33lVXVysvL0/Tpk1zbLNarerfv79yc3NP6l9VVaWqqirH5/Ly8kaJ08xWTH1IBwoKNemfSxzbPlnzvgo2b9Of173qx8gA7zm8/4BemTxLd69erqbh4f4OB/A6vyb7b7/9VrW1tYqNjXXaHhsbq927d5/UPzMzU7Nnz26s8ExvxbSH9NnaHGWsytJZ8XGO7QWbt+nbr/fp3vN/69T/mdEZ6tj7ImWsfLGxQwU8UrTjUx099K3mXjrIsa2utlaFm7dqw9NZevL7PbKGhPgxQniDmR+XG1AP1Zk2bZoyMjIcn8vLy5WQkODHiIKTYRh6+c9zlf/2emWsfEEt27Vx2p9612hdOnKY07YH+w7T9XPuU/cBVzRmqIBXJPa9TNO3rXXatnTsvYrr1FEDMsaR6IOEY+7dg+MDlV+TfcuWLRUSEqLS0lKn7aWlpYqLizupf1hYmMLCwhorPNNaMfUhffTG2xq75HGFNY9U2cFvJUkRUc0VGhEue0zLUy7Kiz4n7qQfBkAgCI9qrnMuSHTaFhrZTJHRZ520HYHLzK+49esCvdDQUPXq1Uvr1v33YSx1dXVat26dUlJS/BiZuW3Melk/lh/V/N/fpqnd+jla3ptr/B0aAKAB/D6Mn5GRobS0NF188cX6zW9+o8cee0yVlZUaNWqUv0MzrUWlOxvlGOBMdu8aFqAGG4vVIosH5TkvwvHAH//4Rx06dEgzZsxQSUmJevbsqTVr1py0aA8AAE+Y+UU4fk/2kpSenq709HR/hwEAQFA6I5I9AAC+RmUPAECQM/Otd35/XC4AAPAtKnsAgCkwjA8AQJBjGB8AAAQtKnsAgCkwjA8AQJCzWiyyepCxPTnW30j2AABTMHNlz5w9AABBjsoeAGAKFnm4Gp8X4QAAcGazWE+0Bh9veC+WxsYwPgAAQY7KHgBgDh4+VCeQV+iR7AEApsBqfAAAELSo7AEApnCisvfk2fheDKaRkewBAKbAMD4AAAhaVPYAAFPg2fgAAAQ5Mw/jk+wBAKZg8fA+e4/u0fcz5uwBAAhyVPYAAFMw8zA+lT0AwBTqk70nzR2ZmZm65JJLFBUVpZiYGA0dOlQFBQVOfY4dO6bx48fr7LPPVvPmzTV8+HCVlpY69SkqKtI111yjZs2aKSYmRpMnT9bx48fdioVkDwCAD+Tk5Gj8+PH68MMPtXbtWtXU1GjAgAGqrKx09Jk4caJWr16tV199VTk5OTpw4ICGDRvm2F9bW6trrrlG1dXV2rJli5YsWaKsrCzNmDHDrVgshmEE7Ev7ysvLZbfbdaRwp2xRUf4OB/AJS/MW/g4B8Jny8nLZW7dVWVmZbDab765ht2t3j/MVFRLS4PMcra1V4idfat++fU6xhoWFKSws7LTHHzp0SDExMcrJyVGfPn1UVlamVq1aafny5br++uslSbt371aXLl2Um5ur3r1765133tHvfvc7HThwQLGxsZKkxYsXa8qUKTp06JBCQ0Ndip3KHgBgCt4axk9ISJDdbne0zMxMl65fVlYmSYqOjpYk5eXlqaamRv3793f0SUxMVNu2bZWbmytJys3NVbdu3RyJXpJSU1NVXl6uzz//3OXvzgI9AADccKrK/nTq6up0zz336NJLL1XXrl0lSSUlJQoNDVWLFi2c+sbGxqqkpMTR538Tff3++n2uItkDAEzBW0/Qs9lsbk85jB8/Xp999pk2b97c4Ot7gmF8AIApNPZq/Hrp6enKzs7W+++/rzZt2ji2x8XFqbq6WkeOHHHqX1paqri4OEefn6/Or/9c38cVJHsAAHzAMAylp6dr5cqVWr9+vdq3b++0v1evXmratKnWrVvn2FZQUKCioiKlpKRIklJSUrRz504dPHjQ0Wft2rWy2WxKSkpyORaG8QEAptDYj8sdP368li9frjfffFNRUVGOOXa73a6IiAjZ7XaNHj1aGRkZio6Ols1m04QJE5SSkqLevXtLkgYMGKCkpCTdfPPNmjdvnkpKSnT//fdr/PjxLq0VqEeyBwCYgkUePkHPzf6LFi2SJPXt29dp+4svvqhbb71VkjR//nxZrVYNHz5cVVVVSk1N1VNPPeXoGxISouzsbI0bN04pKSmKjIxUWlqa5syZ417s3GcPnNm4zx7BrDHvs997caKimnhwn/3xWrXfvtunsfoKc/YAAAQ5hvEBAObg4Ytw3B7HP4OQ7AEApsD77AEAQNCisgcAmILFeqJ5cnygItkDAEyBYXwAABC0qOwBAOZgtZxonhwfoEj2AABz8ORtNvXHByiSPQDAFJizBwAAQYvKHgBgDszZAwAQ5Ew8Z88wPgAAQY7KHgBgCharRRYPhuI9OdbfSPYAAHNgGB8AAAQrKnsAgClYLB4O4wdwZe9Ssv/nP//p8gmvu+66BgcDAIDPmHgY36VkP3ToUJdOZrFYVFtb60k8AADAy1xK9nV1db6OAwAA37LKw4fqeC2SRufRnP2xY8cUHh7urVgAAPAZno3vhtraWj3wwAM655xz1Lx5c3311VeSpOnTp+v555/3eoAAAHhF/eNyPWkByu1k/9BDDykrK0vz5s1TaGioY3vXrl313HPPeTU4AADgObeT/dKlS/XMM89o5MiRCgkJcWzv0aOHdu/e7dXgAADwmvrV+J60AOX2nP0333yjjh07nrS9rq5ONTU1XgkKAABvs1hPNE+OD1Ruh56UlKRNmzadtP21117ThRde6JWgAACA97hd2c+YMUNpaWn65ptvVFdXpzfeeEMFBQVaunSpsrOzfREjAACeM/FDddyu7IcMGaLVq1frvffeU2RkpGbMmKFdu3Zp9erVuvrqq30RIwAAHqt/650nLVA16D77yy+/XGvXrvV2LAAAwAca/FCd7du3a9euXZJOzOP36tXLa0EBAOB1Jh7GdzvZ79+/XzfeeKM++OADtWjRQpJ05MgR/fa3v9WKFSvUpk0bb8cIAIDnPH0wTgAP47s9Z3/77berpqZGu3bt0uHDh3X48GHt2rVLdXV1uv32230RIwAA8IDblX1OTo62bNmizp07O7Z17txZTzzxhC6//HKvBgcAgLeY+dn4bif7hISEUz48p7a2VvHx8V4JCgAAr2MY33WPPPKIJkyYoO3btzu2bd++XXfffbceffRRrwYHAID3ePqo3MBN9i5V9meddZbT8EVlZaWSk5PVpMmJw48fP64mTZrotttu09ChQ30SKAAAaBiXkv1jjz3m4zAAAPAt5uxPIy0tzddxAADgWyaes2/wQ3Uk6dixY6qurnbaZrPZPAoIAAB4l9sL9CorK5Wenq6YmBhFRkbqrLPOcmoAAJyJ6ofxPWmByu1kf99992n9+vVatGiRwsLC9Nxzz2n27NmKj4/X0qVLfREjAACeqx/G96QFKLeH8VevXq2lS5eqb9++GjVqlC6//HJ17NhR7dq107JlyzRy5EhfxAkAABrI7cr+8OHD6tChg6QT8/OHDx+WJF122WXauHGjd6MDAMBbPLnH3tOX6PiZ28m+Q4cO2rt3ryQpMTFRr7zyiqQTFX/9i3EAADjTmPl99m4n+1GjRumTTz6RJE2dOlULFy5UeHi4Jk6cqMmTJ3s9QAAA4Bm35+wnTpzo+HP//v21e/du5eXlqWPHjurevbtXgwMAwGt4n33DtWvXTu3atfNGLAAA+I5VHj5Ux2uRNDqXkv2CBQtcPuFdd93V4GAAAPAVHpd7GvPnz3fpZBaLhWQPAMAZxqVkX7/6/kxlibTL0pzH9CI4jY1s4+8QAJ+pltF4F2vkZ+Nv3LhRjzzyiPLy8lRcXKyVK1c6vRn21ltv1ZIlS5yOSU1N1Zo1axyfDx8+rAkTJmj16tWyWq0aPny4Hn/8cTVv3ty90N3qDQBAoGrk++wrKyvVo0cPLVy48Bf7DBw4UMXFxY72j3/8w2n/yJEj9fnnn2vt2rXKzs7Wxo0bdccdd7j91T1eoAcAAE42aNAgDRo06Ff7hIWFKS4u7pT7du3apTVr1uijjz7SxRdfLEl64oknNHjwYD366KOKj493ORYqewCAOXipsi8vL3dqVVVVDQ5pw4YNiomJUefOnTVu3Dh99913jn25ublq0aKFI9FLJ255t1qt2rp1q1vXIdkDAEzC00R/ItknJCTIbrc7WmZmZoOiGThwoJYuXap169bpr3/9q3JycjRo0CDV1tZKkkpKShQTE+N0TJMmTRQdHa2SkhK3rsUwPgAAbti3b59stv8uCg8LC2vQeUaMGOH4c7du3dS9e3edd9552rBhg6666iqP4/xfDarsN23apJtuukkpKSn65ptvJEkvvfSSNm/e7NXgAADwGqvV86YTL4H739bQZP9zHTp0UMuWLVVYWChJiouL08GDB536HD9+XIcPH/7Fef5f/OruBvP6668rNTVVERER2rFjh2OuoqysTHPnznX3dAAANI4z/K13+/fv13fffafWrVtLklJSUnTkyBHl5eU5+qxfv151dXVKTk5269xuJ/sHH3xQixcv1rPPPqumTZs6tl966aX6+OOP3T0dAABBqaKiQvn5+crPz5d04pk1+fn5KioqUkVFhSZPnqwPP/xQX3/9tdatW6chQ4aoY8eOSk1NlSR16dJFAwcO1JgxY7Rt2zZ98MEHSk9P14gRI9xaiS81INkXFBSoT58+J2232+06cuSIu6cDAKBxNHJlv337dl144YW68MILJUkZGRm68MILNWPGDIWEhOjTTz/Vddddp06dOmn06NHq1auXNm3a5DQtsGzZMiUmJuqqq67S4MGDddlll+mZZ55x+6u7vUAvLi5OhYWFOvfcc522b968WR06dHA7AAAAGkUjv/Wub9++MoxffkLgu+++e9pzREdHa/ny5W5d91TcruzHjBmju+++W1u3bpXFYtGBAwe0bNkyTZo0SePGjfM4IAAAfMJLC/QCkduV/dSpU1VXV6errrpKP/zwg/r06aOwsDBNmjRJEyZM8EWMAADAA24ne4vFor/85S+aPHmyCgsLVVFRoaSkJLcfyg8AQKNq5GH8M0mDH6oTGhqqpKQkb8YCAIDvkOxd169fP1l+5QuvX7/eo4AAAIB3uZ3se/bs6fS5pqZG+fn5+uyzz5SWluatuAAA8C4qe9fNnz//lNtnzZqliooKjwMCAMAnPF1RH8Cr8b0W+U033aQXXnjBW6cDAABe4rW33uXm5io8PNxbpwMAwLsYxnfdsGHDnD4bhqHi4mJt375d06dP91pgAAB4lUUeJnuvRdLo3E72drvd6bPValXnzp01Z84cDRgwwGuBAQAA73Ar2dfW1mrUqFHq1q2bzjrrLF/FBACA95l4GN+tBXohISEaMGAAb7cDAAQci9XqcQtUbkfetWtXffXVV76IBQAAH/L09bYmqewl6cEHH9SkSZOUnZ2t4uJilZeXOzUAAHBmcXnOfs6cObr33ns1ePBgSdJ1113n9NhcwzBksVhUW1vr/SgBAPCUiefsXU72s2fP1tixY/X+++/7Mh4AAHyDZH96hmFIkq644gqfBQMAALzPrVvvfu1tdwAAnNFM/Gx8t5J9p06dTpvwDx8+7FFAAAD4BMP4rpk9e/ZJT9ADAABnNreS/YgRIxQTE+OrWAAA8B0q+9Njvh4AENBMnOxdXm1QvxofAAAEFpcr+7q6Ol/GAQCAb7EaHwCAIGfiYXySPQDAHEyc7AN3TAIAALiEyh4AYA7M2QMAEOQs8nAY32uRNLrA/ZkCAABcQmUPADAHEy/QI9kDAMzBxMmeYXwAAIIclT0AwBwsHq7GtwRufUyyBwCYA8P4AAAgWFHZAwDMwcSVPckeAGAOFqtn8+7M2QMAcIazWk40T44PUIH7MwUAALiEyh4AYA4M4wMAEORMvEAvcH+mAAAAl1DZAwDMgffZAwAQ5BjGBwAAwYrKHgBgDqzGBwAgyFnk4TC+1yJpdIH7MwUAALiEyh4AYA4mXo0fuJEDAOCO+tX4njQ3bNy4Uddee63i4+NlsVi0atUqp/2GYWjGjBlq3bq1IiIi1L9/f3355ZdOfQ4fPqyRI0fKZrOpRYsWGj16tCoqKtz+6iR7AIA51C/Q86S5obKyUj169NDChQtPuX/evHlasGCBFi9erK1btyoyMlKpqak6duyYo8/IkSP1+eefa+3atcrOztbGjRt1xx13uP3VGcYHAMAHBg0apEGDBp1yn2EYeuyxx3T//fdryJAhkqSlS5cqNjZWq1at0ogRI7Rr1y6tWbNGH330kS6++GJJ0hNPPKHBgwfr0UcfVXx8vMuxUNkDAMzBYvnva24b0n4axi8vL3dqVVVVboeyd+9elZSUqH///o5tdrtdycnJys3NlSTl5uaqRYsWjkQvSf3795fVatXWrVvduh7JHgBgDl4axk9ISJDdbne0zMxMt0MpKSmRJMXGxjptj42NdewrKSlRTEyM0/4mTZooOjra0cdVDOMDAOCGffv2yWazOT6HhYX5MRrXUNkDAMzBS6vxbTabU2tIso+Li5MklZaWOm0vLS117IuLi9PBgwed9h8/flyHDx929HEVyR4AYA6NvBr/17Rv315xcXFat26dY1t5ebm2bt2qlJQUSVJKSoqOHDmivLw8R5/169errq5OycnJbl2PYXwAAHygoqJChYWFjs979+5Vfn6+oqOj1bZtW91zzz168MEHdf7556t9+/aaPn264uPjNXToUElSly5dNHDgQI0ZM0aLFy9WTU2N0tPTNWLECLdW4kskewCAWdSvqvfkeDds375d/fr1c3zOyMiQJKWlpSkrK0v33XefKisrdccdd+jIkSO67LLLtGbNGoWHhzuOWbZsmdLT03XVVVfJarVq+PDhWrBggduhWwzDMNw+6gxRXl4uu92usuIip8USQDAZG9nG3yEAPlMtQy+qUmVlZT77d7w+VxzOeki2ZuGnP+CXzvPDMUXf+hefxuorzNkDABDkGMYHAJgD77MHACDINfKc/ZmEZA8AMAeLxcPKPnCTfeCOSQAAAJdQ2QMAzKEB76Q/6fgARbIHAJiDiRfoBW7kAADAJVT2AABzYDU+AABBjmF8AAAQrKjsAQDmwGp8AACCnNV6onlyfIAK3MgBAIBLSPZw25pHF2psZIJemTzL36EAp9Xn9pt1/9a1ml+8S/OLd+m+9W/qggH/fcd4k7Awjfj7g3q0aKceKy3QHcueUVRMS8f+yOgWmrDq/+nhwu164vAezS3YphF/e1DhUc398XXgEct/h/Ib0hS4w/h+TfYbN27Utddeq/j4eFksFq1atcqf4cAFX+fla9MLy3RO1y7+DgVwyfffFGvVjExlXjZYmZcPVkHOBxr38vNq3aWTJOkPf52p7oOv1rM3/5/+nnq9WrSO1djlzzqON+oMfZL9rp76w22a2aOPlvzfRCX2u0x/WvCwv74SGqp+Nb4nLUD5NfLKykr16NFDCxcu9GcYcNGxikq9cNtduunJv6rZWXZ/hwO4ZOc77+mzd9fr4J69Oli4V2/Onqeqih/U/pKLFG6L0qVpI/Ta1DkqyNmiovydWjI2Q+elXKL2l1wkSfrhSJk2PveSinZ8qsP7vlHBhg+U8+xSdfztb/z8zeA2T6p6Txf3+Zlfk/2gQYP04IMP6ve//70/w4CLVky8X11Tr1SXKy/3dyhAg1isVl18/XUKjYzQ3m15andhNzUJDdWu9zc5+pT+e4++K9qvDskXnfIc9rhYXXjdIH25+cPGChvwWECtxq+qqlJVVZXjc3l5uR+jMZePXn1TRfk7NW1Ttr9DAdwWf0Gi7lv/ppqGh6mqolJP3zhGxbu/VJvuF6imqko/ljn/W3L04LeyxcY4bRud9aR6XJOq0GYR+uStf+mlOyc35leAN7AaPzBkZmbKbrc7WkJCgr9DMoXD+w/olcmzdNsLT6hpeLi/wwHcVvrvPXooJVV/veJabXzuJaU9PV+tE8936xyvTpmthy4dqKf+MEqt2rfTHx6e4aNo4TMmHsYPqMp+2rRpysjIcHwuLy8n4TeCoh2f6uihbzX30kGObXW1tSrcvFUbns7Sk9/vkTUkxI8RAr+utqZGh776WpJUlL9T7Xr1UL87Ryvv9X+qaViYIuw2p+o+KqalyksPOp2jvPSQyksPqfTfe1T5/RFNfm+l3vrr4yovce4HnIkCKtmHhYUpLCzM32GYTmLfyzR921qnbUvH3qu4Th01IGMciR4Bx2K1qmlYqP6zY6eOV1crse9l2vHm25Kk2PM76Oy2bfTV1o9/9XhJahoa2ijxwkssFg+fjU9ljyAWHtVc51yQ6LQtNLKZIqPPOmk7cKYZOnuqPvvX+/p+3zcKi2qu39wwVJ0uT9ETQ0bqWPlRfbBkha5/eIYqvz+iY+VH9ce/PaA9H27X3o9OJPuuqVcqKqal/pP3iaoqKtW6SycNf+h+FW7Zpu+K9vv528EtPC7XPyoqKlRYWOj4vHfvXuXn5ys6Olpt27b1Y2QAgkVUq5Ya9exjssXF6Mfyo/rms116YshI7Vp/YgX+q1Nmy6ir0/8te0ZNwkL1xXs5+sfEPzuOr/7xmC679U/6w8Mz1SQsTN/vP6Ad/3xH7/6NW4YROCyGYRj+uviGDRvUr1+/k7anpaUpKyvrtMeXl5fLbrerrLhINpvNBxEC/jc2so2/QwB8plqGXlSlysrKfPbveH2uOJz9vGyRzRp+nsofFP270T6N1Vf8Wtn37dtXfvytAQAwE6vlRPPk+AAVULfeAQAA97FADwBgDp4+3z6An41PsgcAmAOr8QEACHImruwDN3IAAOASKnsAgClYLBZZPBiK9+RYfyPZAwDMgWF8AAAQrKjsAQDmYOLKnmQPADAHi4dP0AvgOfvA/ZkCAABcQmUPADAHhvEBAAhyJn6CXuD+TAEAAC6hsgcAmIPF4uEwfuBW9iR7AIA5mHgYn2QPADAHEy/QC9zIAQCAS6jsAQDmYPXwoTqeHOtnJHsAgDkwjA8AAIIVlT0AwBxYjQ8AQJBjGB8AAAQrKnsAgDmYeBifyh4AYA71w/ieNDfMmjVLFovFqSUmJjr2Hzt2TOPHj9fZZ5+t5s2ba/jw4SotLfX2t5ZEsgcAwGcuuOACFRcXO9rmzZsd+yZOnKjVq1fr1VdfVU5Ojg4cOKBhw4b5JA6G8QEA5mC1nmieHO+mJk2aKC4u7qTtZWVlev7557V8+XJdeeWVkqQXX3xRXbp00YcffqjevXs3PM5ToLIHAJjCz4fUG9Ikqby83KlVVVX94jW//PJLxcfHq0OHDho5cqSKiookSXl5eaqpqVH//v0dfRMTE9W2bVvl5uZ6/buT7AEA5lD/itsGtxPJPiEhQXa73dEyMzNPebnk5GRlZWVpzZo1WrRokfbu3avLL79cR48eVUlJiUJDQ9WiRQunY2JjY1VSUuL1r84wPgAAbti3b59sNpvjc1hY2Cn7DRo0yPHn7t27Kzk5We3atdMrr7yiiIgIn8f5v6jsAQDmUH/rnSdNks1mc2q/lOx/rkWLFurUqZMKCwsVFxen6upqHTlyxKlPaWnpKef4PUWyBwCYhKe33XmWMisqKrRnzx61bt1avXr1UtOmTbVu3TrH/oKCAhUVFSklJcXD73kyhvEBAPCBSZMm6dprr1W7du104MABzZw5UyEhIbrxxhtlt9s1evRoZWRkKDo6WjabTRMmTFBKSorXV+JLJHsAgFk08hP09u/frxtvvFHfffedWrVqpcsuu0wffvihWrVqJUmaP3++rFarhg8frqqqKqWmpuqpp55qeHy/gmQPADCHRr7PfsWKFb+6Pzw8XAsXLtTChQsbHpOLmLMHACDIUdkDAMzBxC/CIdkDAMyB99kDAIBgRWUPADAHhvEBAAh2lp+aJ8cHJpI9AMAcTFzZM2cPAECQo7IHAJiDiSt7kj0AwCTMO2fPMD4AAEGOyh4AYA4M4wMAEOTMO4rPMD4AAMGOyh4AYBLmLe1J9gAAczDxnD3D+AAABDkqewCAOVjkYWXvtUgaHckeAGASzNkDABDcmLMHAADBisoeAGASDOMDABDcGMYHAADBisoeAGAOJq7sSfYAAJMw75w9w/gAAAQ5KnsAgClYLBZZPBiK9+RYfyPZAwDMwcRz9gzjAwAQ5KjsAQAmYd4FeiR7AIBJeDiMT7IHAOAMx5w9AAAIVlT2AACTYM4eAIDgxjA+AAAIVlT2AABzMO8oPskeAGAW5s32DOMDABDkqOwBAOZg4gV6JHsAgDmYONkzjA8AQJCjsgcAmIR5F+iR7AEA5mCRh8P4Xouk0ZHsAQDmwJw9AAAIVlT2AACTYM4eAIDgZuJh/IBO9oZhSJLKjx71cySA71TL8HcIgM/U//2u//fclzzNFYGcawI62R/96X98QqcL/BwJAMATR48eld1u98m5Q0NDFRcX55VcERcXp9DQUC9E1bgsRmP8nPKRuro6HThwQFFRUbIE8PBKICkvL1dCQoL27dsnm83m73AAr+Lvd+MzDENHjx5VfHy8rFbfrRk/duyYqqurPT5PaGiowsPDvRBR4wroyt5qtapNmzb+DsOUbDYb/xgiaPH3u3H5qqL/X+Hh4QGZpL2FW+8AAAhyJHsAAIIcyR5uCQsL08yZMxUWFubvUACv4+83glVAL9ADAACnR2UPAECQI9kDABDkSPYAAAQ5kj0AAEGOZA+XLVy4UOeee67Cw8OVnJysbdu2+TskwCs2btyoa6+9VvHx8bJYLFq1apW/QwK8imQPl7z88svKyMjQzJkz9fHHH6tHjx5KTU3VwYMH/R0a4LHKykr16NFDCxcu9HcogE9w6x1ckpycrEsuuURPPvmkpBPvJUhISNCECRM0depUP0cHeI/FYtHKlSs1dOhQf4cCeA2VPU6rurpaeXl56t+/v2Ob1WpV//79lZub68fIAACuINnjtL799lvV1tYqNjbWaXtsbKxKSkr8FBUAwFUkewAAghzJHqfVsmVLhYSEqLS01Gl7aWmp4uLi/BQVAMBVJHucVmhoqHr16qV169Y5ttXV1WndunVKSUnxY2QAAFc08XcACAwZGRlKS0vTxRdfrN/85jd67LHHVFlZqVGjRvk7NMBjFRUVKiwsdHzeu3ev8vPzFR0drbZt2/oxMsA7uPUOLnvyySf1yCOPqKSkRD179tSCBQuUnJzs77AAj23YsEH9+vU7aXtaWpqysrIaPyDAy0j2AAAEOebsAQAIciR7AACCHMkeAIAgR7IHACDIkewBAAhyJHsAAIIcyR4AgCBHsgcAIMiR7AEP3XrrrRo6dKjjc9++fXXPPfc0ehwbNmyQxWLRkSNHfrGPxWLRqlWrXD7nrFmz1LNnT4/i+vrrr2WxWJSfn+/ReQA0HMkeQenWW2+VxWKRxWJRaGioOnbsqDlz5uj48eM+v/Ybb7yhBx54wKW+riRoAPAUL8JB0Bo4cKBefPFFVVVV6e2339b48ePVtGlTTZs27aS+1dXVCg0N9cp1o6OjvXIeAPAWKnsErbCwMMXFxaldu3YaN26c+vfvr3/+85+S/jv0/tBDDyk+Pl6dO3eWJO3bt0833HCDWrRooejoaA0ZMkRff/2145y1tbXKyMhQixYtdPbZZ+u+++7Tz18v8fNh/KqqKk2ZMkUJCQkKCwtTx44d9fzzz+vrr792vHzlrLPOksVi0a233irpxCuEMzMz1b59e0VERKhHjx567bXXnK7z9ttvq1OnToqIiFC/fv2c4nTVlClT1KlTJzVr1kwdOnTQ9OnTVVNTc1K/p59+WgkJCWrWrJluuOEGlZWVOe1/7rnn1KVLF4WHhysxMVFPPfWU27EA8B2SPUwjIiJC1dXVjs/r1q1TQUGB1q5dq+zsbNXU1Cg1NVVRUVHatGmTPvjgAzVv3lwDBw50HPe3v/1NWVlZeuGFF7R582YdPnxYK1eu/NXr3nLLLfrHP/6hBQsWaNeuXXr66afVvHlzJSQk6PXXX5ckFRQUqLi4WI8//rgkKTMzU0uXLtXixYv1+eefa+LEibrpppuUk5Mj6cSPkmHDhunaa69Vfn6+br/9dk2dOtXt/ydRUVHKysrSF198occff1zPPvus5s+f79SnsLBQr7zyilavXq01a9Zox44duvPOOx37ly1bphkzZuihhx7Srl27NHfuXE2fPl1LlixxOx4APmIAQSgtLc0YMmSIYRiGUVdXZ6xdu9YICwszJk2a5NgfGxtrVFVVOY556aWXjM6dOxt1dXWObVVVVUZERITx7rvvGoZhGK1btzbmzZvn2F9TU2O0adPGcS3DMIwrrrjCuPvuuw3DMIyCggJDkrF27dpTxvn+++8bkozvv//ese3YsWNGs2bNjC1btjj1HT16tHHjjTcahmEY06ZNM5KSkpz2T5ky5aRz/ZwkY+XKlb+4/5FHHjF69erl+Dxz5kwjJCTE2L9/v2PbO++8Y1itVqO4uNgwDMM477zzjOXLlzud54EHHjBSUlIMwzCMvXv3GpKMHTt2/OJ1AfgWc/YIWtnZ2WrevLlqampUV1enP/3pT5o1a5Zjf7du3Zzm6T/55BMVFhYqKirK6TzHjh3Tnj17VFZWpuLiYiUnJzv2NWnSRBdffPFJQ/n18vPzFRISoiuuuMLluAsLC/XDDz/o6quvdtpeXV2tCy+8UJK0a9cupzgkKSUlxeVr1Hv55Ze1YMEC7dmzRxUVFTp+/LhsNptTn7Zt2+qcc85xuk5dXZ0KCgoUFRWlPXv2aPTo0RozZoyjz/Hjx2W3292OB4BvkOwRtPr166dFixYpNDRU8fHxatLE+a97ZGSk0+eKigr16tVLy5YtO+lcrVq1alAMERERbh9TUVEhSXrrrbeckqx0Yh2Ct+Tm5mrkyJGaPXu2UlNTZbfbtWLFCv3tb39zO9Znn332pB8fISEhXosVgGdI9ghakZGR6tixo8v9L7roIr388suKiYk5qbqt17p1a23dulV9+vSRdKKCzcvL00UXXXTK/t26dVNdXZ1ycnLUv3//k/bXjyzU1tY6tiUlJSksLExFRUW/OCLQpUsXx2LDeh9++OHpv+T/2LJli9q1a6e//OUvjm3/+c9/TupXVFSkAwcOKD4+3nEdq9Wqzp07KzY2VvHx8frqq680cuRIt64PoPGwQA/4yciRI9WyZUsNGTJEmzZt0t69e7Vhwwbddddd2r9/vyTp7rvv1sMPP6xVq1Zp9+7duvPOO3/1Hvlzzz1XaWlpuu2227Rq1SrHOV955RVJUrt27WSxWJSdna1Dhw6poqJCUVFRmjRpkiZOnKglS5Zoz549+vjjj/XEE084Fr2NHTtWX375pSZPnqyCggItX75cWVlZbn3f888/X0VFRVqxYoX27NmjBQsWnHKxYXh4uNLS0vTJJ59o06ZNuuuuu3TDDTcoLi5OkjR79mxlZmZqwYIF+ve//62dO3fqxRdf1N///ne34gHgOyR74CfNmjXTxo0b1bZtWw0bNkxdunTR6NGjdezYMUelf++99+rmm29WWlqaUlJSFBUVpd///ve/et5Fixbp+uuv15133qnExESNGTNGlZWVkqRzzjlHs2fP1tSpUxUbG6v09HRJ0gMPPKDp06crMzNTXbp00cCBA/XWW2+pffv2kk7Mo7/++utatWqVevToocWLF2vu3Llufd/rrrtOEydOVHp6unr27KktW7Zo+vTpJ/Xr2LGjhg0bpsGDB2vAgAHq3r270611t99+u5577jm9+OKL6tatm6644gplZWU5YgXgfxbjl1YWAQCAoEBlDwBAkCPZAwAQ5Ej2AAAEOZI9AABBjmQPAECQI9kDABDkSPYAAAQ5kj0AAEGOZA8AQJAj2QMAEORI9gAABLn/DzWL5gpZNFKfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(conf_mtx)\n",
    "cm_disp.plot(cmap = \"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 4 303 4\n"
     ]
    }
   ],
   "source": [
    "TP = conf_mtx[0][0]\n",
    "FP = conf_mtx[1][0]\n",
    "TN = conf_mtx[1][1]\n",
    "FN = conf_mtx[0][1]\n",
    "\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Precision is calculated as follows: $$ \\frac{TP}{(TP + FP)} $$\n",
    "\n",
    "Recall is calculated as follows: $$ \\frac{TP}{(TP + FN)} $$\n",
    "\n",
    "f1Score is calculated as follows: $$ \\frac{Precision * Recall}{(Precision + Recall)} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8571428571428571\n",
      "Recall: 0.8571428571428571\n",
      "f1score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1score: {f1score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47e47cda05e9886a0f1932160b1f70f95aa1d71424dff224d867803480b36f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
