{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-NBA Team Binary Classification Model\n",
    "\n",
    "Will use various classification algorithms(logisitic regression, KNN, SVM, etc) and evaluate performance on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.metrics import *\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze dataset\n",
    "\n",
    "Preview features (player, games started, minutes played, etc.) and training examples (the players)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>GPnS%</th>\n",
       "      <th>GPnSround%</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>61</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Adams</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>58</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>58</td>\n",
       "      <td>27.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>64</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>64</td>\n",
       "      <td>33.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>26</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>23</td>\n",
       "      <td>25.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player   G     GPnS%  GPnSround%  GS    MP   FG   FGA    FG%  \\\n",
       "0   Precious Achiuwa  61  0.055556      0.0556   4  12.1  2.0   3.7  0.544   \n",
       "1       Jaylen Adams   7  0.000000      0.0000   0   2.6  0.1   1.1  0.125   \n",
       "2       Steven Adams  58  0.805556      0.8056  58  27.7  3.3   5.3  0.614   \n",
       "3        Bam Adebayo  64  0.888889      0.8889  64  33.5  7.1  12.5  0.570   \n",
       "4  LaMarcus Aldridge  26  0.319444      0.3194  23  25.9  5.4  11.4  0.473   \n",
       "\n",
       "    3P  ...  STL  BLK  TOV   PF   PTS   PER   WS   BPM  VORP  All-NBA?  \n",
       "0  0.0  ...  0.3  0.5  0.7  1.5   5.0  14.2  1.3  -4.5  -0.5         0  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.1   0.3  -6.5 -0.1 -19.8  -0.1         0  \n",
       "2  0.0  ...  0.9  0.7  1.3  1.9   7.6  15.1  4.0  -0.8   0.5         0  \n",
       "3  0.0  ...  1.2  1.0  2.6  2.3  18.7  22.7  8.8   4.7   3.6         0  \n",
       "4  1.2  ...  0.4  1.1  1.0  1.8  13.5  15.7  1.1  -0.6   0.2         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = \"../Data/DataSet.csv\"\n",
    "df = pd.read_csv(DATADIR) # read dataset\n",
    "df.head() # preview first few features and rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at list of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Player', 'G', 'GPnS%', 'GPnSround%', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
       "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'TRB', 'AST', 'STL',\n",
       "       'BLK', 'TOV', 'PF', 'PTS', 'PER', 'WS', 'BPM', 'VORP', 'All-NBA?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # list of columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove player column from dataset and store it in numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = df.pop('Player') # remove Player column from dataSet and store in players\n",
    "players = np.array(players) # cast players from list into numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine players numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Precious Achiuwa', 'Jaylen Adams', 'Steven Adams', ...,\n",
       "       'Andre Drummond', 'Klay Thompson', 'Kyle Lowry'], dtype=object)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find correlation between features and target variable\n",
    "\n",
    "Use a correlation matrix to determine the features with the strongest correlation to the target variable (All-NBA?). Look at the leftmost and rightmost column to analyze strongest features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G             0.275890\n",
       "GPnS%         0.454324\n",
       "GPnSround%    0.454319\n",
       "GS            0.471530\n",
       "MP            0.402598\n",
       "FG            0.551768\n",
       "FGA           0.524672\n",
       "FG%           0.127382\n",
       "3P            0.297344\n",
       "3PA           0.297626\n",
       "3P%           0.061744\n",
       "2P            0.540380\n",
       "2PA           0.532232\n",
       "2P%           0.087835\n",
       "eFG%          0.100872\n",
       "TRB           0.418248\n",
       "AST           0.475572\n",
       "STL           0.435999\n",
       "BLK           0.274642\n",
       "TOV           0.535496\n",
       "PF            0.219371\n",
       "PTS           0.581269\n",
       "PER           0.420605\n",
       "WS            0.703642\n",
       "BPM           0.382282\n",
       "VORP          0.779935\n",
       "All-NBA?      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataSet.corr()    this prints the correlation matrix for all other features\n",
    "df.corrwith(df[\"All-NBA?\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Choose features based on strongest correlation with target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all rows and only the listed colums\n",
    "df = df.loc[:, [\"GS\", \"FG\", \"FGA\", \"2P\", \"2PA\", \"AST\", \n",
    "                \"TOV\", \"PTS\", \"WS\", \"VORP\", \"All-NBA?\"]] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Develop new features based on existing features. For example, the AST/TOV ratio is a commonly used statistic in evaluating the playmaking ability of a player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AST/TOV'] = df.apply(lambda x: x['AST'] / x['TOV'] if x['TOV'] != 0 else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.714286\n",
       "1       1.000000\n",
       "2       1.461538\n",
       "3       2.076923\n",
       "4       1.900000\n",
       "          ...   \n",
       "1110    1.242424\n",
       "1111    1.153846\n",
       "1112    0.421053\n",
       "1113    1.235294\n",
       "1114    2.206897\n",
       "Name: AST/TOV, Length: 1115, dtype: float64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AST/TOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GS          0.471530\n",
       "FG          0.551768\n",
       "FGA         0.524672\n",
       "2P          0.540380\n",
       "2PA         0.532232\n",
       "AST         0.475572\n",
       "TOV         0.535496\n",
       "PTS         0.581269\n",
       "WS          0.703642\n",
       "VORP        0.779935\n",
       "All-NBA?    1.000000\n",
       "AST/TOV     0.024009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['All-NBA?'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AST/TOV doesn't have a strong positive correlation with making an All-NBA team, so we'll discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>AST</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WS</th>\n",
       "      <th>VORP</th>\n",
       "      <th>All-NBA?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>81</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>81</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>80</td>\n",
       "      <td>8.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>77</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GS   FG   FGA   2P   2PA  AST  TOV   PTS    WS  VORP  All-NBA?\n",
       "0      4  2.0   3.7  2.0   3.7  0.5  0.7   5.0   1.3  -0.5         0\n",
       "1      0  0.1   1.1  0.1   0.9  0.3  0.0   0.3  -0.1  -0.1         0\n",
       "2     58  3.3   5.3  3.3   5.3  1.9  1.3   7.6   4.0   0.5         0\n",
       "3     64  7.1  12.5  7.1  12.4  5.4  2.6  18.7   8.8   3.6         0\n",
       "4     23  5.4  11.4  4.2   8.3  1.9  1.0  13.5   1.1   0.2         0\n",
       "...   ..  ...   ...  ...   ...  ...  ...   ...   ...   ...       ...\n",
       "1110  81  7.5  17.9  4.9  10.9  4.1  3.3  23.1   9.2   4.9         1\n",
       "1111  74  7.2  14.1  7.2  13.9  1.5  1.3  18.0  10.1   2.5         1\n",
       "1112  81  6.8  13.1  6.8  13.0  0.8  1.9  16.2   7.4   2.0         1\n",
       "1113  80  8.1  17.3  4.7   9.2  2.1  1.7  22.1   8.0   2.5         1\n",
       "1114  77  6.6  15.6  3.9   8.5  6.4  2.9  21.2  11.6   5.0         1\n",
       "\n",
       "[1115 rows x 11 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('AST/TOV', axis = 1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Scale features so that they have a uniform range. In this case we'll use Z-score normalization, which uses the following equation: $$ x_{n} = \\frac{x_{n} - \\mu_{n}}{\\sigma_{n}} $$\n",
    "where $ x_n $ is the row of the nth column, $ \\mu_{n} $ is the mean of the nth column, and $ \\sigma_{n} $ is the standard deviation of the nth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df.drop(\"All-NBA?\", axis = 1)\n",
    "for col in features_df:\n",
    "    df[col] = (df[col] - np.mean(df[col])) / np.std(df[col])\n",
    "len(features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Data/min_values.npy', df.min().values)\n",
    "np.save('../Data/max_values.npy', df.max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.data[idx]     # Replace with your input feature data\n",
    "        target_sample = self.labels[idx]  # Replace with your target label data\n",
    "\n",
    "        return {'input': input_sample, 'target': target_sample}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate target variable from features and convert to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "X = df[['GS', 'FG', 'FGA', '2P', '2PA', 'AST', 'TOV', 'PTS', 'WS', 'VORP']].values  \n",
    "Y = df[['All-NBA?']].values  \n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test data split and create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 1.0 - train_ratio\n",
    "\n",
    "num_samples = len(dataset)\n",
    "train_size = int(train_ratio * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "X_train, Y_train = train_dataset.dataset[train_dataset.indices]\n",
    "X_test, Y_test = test_dataset.dataset[test_dataset.indices]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We'll use a sequential neural network with 2 hidden layers and a sigmoid activation function for the output layer for the binary classification. Binary Cross Entropy Loss is the used loss function, while adam is the optimizer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = CustomModel(len(features_df.columns), 32, 16)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network\n",
    "\n",
    "Perform forward propagation and back propagation when training neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.6516\n",
      "Epoch [2/100], Training Loss: 0.5956\n",
      "Epoch [3/100], Training Loss: 0.5319\n",
      "Epoch [4/100], Training Loss: 0.4635\n",
      "Epoch [5/100], Training Loss: 0.3825\n",
      "Epoch [6/100], Training Loss: 0.3103\n",
      "Epoch [7/100], Training Loss: 0.2605\n",
      "Epoch [8/100], Training Loss: 0.2137\n",
      "Epoch [9/100], Training Loss: 0.1869\n",
      "Epoch [10/100], Training Loss: 0.1618\n",
      "Epoch [11/100], Training Loss: 0.1539\n",
      "Epoch [12/100], Training Loss: 0.1264\n",
      "Epoch [13/100], Training Loss: 0.1271\n",
      "Epoch [14/100], Training Loss: 0.1113\n",
      "Epoch [15/100], Training Loss: 0.1003\n",
      "Epoch [16/100], Training Loss: 0.0922\n",
      "Epoch [17/100], Training Loss: 0.1000\n",
      "Epoch [18/100], Training Loss: 0.0859\n",
      "Epoch [19/100], Training Loss: 0.0775\n",
      "Epoch [20/100], Training Loss: 0.0723\n",
      "Epoch [21/100], Training Loss: 0.0683\n",
      "Epoch [22/100], Training Loss: 0.0663\n",
      "Epoch [23/100], Training Loss: 0.0716\n",
      "Epoch [24/100], Training Loss: 0.0670\n",
      "Epoch [25/100], Training Loss: 0.0600\n",
      "Epoch [26/100], Training Loss: 0.0639\n",
      "Epoch [27/100], Training Loss: 0.0565\n",
      "Epoch [28/100], Training Loss: 0.0634\n",
      "Epoch [29/100], Training Loss: 0.0550\n",
      "Epoch [30/100], Training Loss: 0.0570\n",
      "Epoch [31/100], Training Loss: 0.0537\n",
      "Epoch [32/100], Training Loss: 0.0506\n",
      "Epoch [33/100], Training Loss: 0.0573\n",
      "Epoch [34/100], Training Loss: 0.0664\n",
      "Epoch [35/100], Training Loss: 0.0510\n",
      "Epoch [36/100], Training Loss: 0.0531\n",
      "Epoch [37/100], Training Loss: 0.0472\n",
      "Epoch [38/100], Training Loss: 0.0516\n",
      "Epoch [39/100], Training Loss: 0.0463\n",
      "Epoch [40/100], Training Loss: 0.0472\n",
      "Epoch [41/100], Training Loss: 0.0454\n",
      "Epoch [42/100], Training Loss: 0.0639\n",
      "Epoch [43/100], Training Loss: 0.0463\n",
      "Epoch [44/100], Training Loss: 0.0442\n",
      "Epoch [45/100], Training Loss: 0.0471\n",
      "Epoch [46/100], Training Loss: 0.0477\n",
      "Epoch [47/100], Training Loss: 0.0456\n",
      "Epoch [48/100], Training Loss: 0.0466\n",
      "Epoch [49/100], Training Loss: 0.0449\n",
      "Epoch [50/100], Training Loss: 0.0422\n",
      "Epoch [51/100], Training Loss: 0.0428\n",
      "Epoch [52/100], Training Loss: 0.0430\n",
      "Epoch [53/100], Training Loss: 0.0479\n",
      "Epoch [54/100], Training Loss: 0.0418\n",
      "Epoch [55/100], Training Loss: 0.0571\n",
      "Epoch [56/100], Training Loss: 0.0500\n",
      "Epoch [57/100], Training Loss: 0.0484\n",
      "Epoch [58/100], Training Loss: 0.0408\n",
      "Epoch [59/100], Training Loss: 0.0481\n",
      "Epoch [60/100], Training Loss: 0.0402\n",
      "Epoch [61/100], Training Loss: 0.0418\n",
      "Epoch [62/100], Training Loss: 0.0404\n",
      "Epoch [63/100], Training Loss: 0.0526\n",
      "Epoch [64/100], Training Loss: 0.0431\n",
      "Epoch [65/100], Training Loss: 0.0389\n",
      "Epoch [66/100], Training Loss: 0.0410\n",
      "Epoch [67/100], Training Loss: 0.0406\n",
      "Epoch [68/100], Training Loss: 0.0393\n",
      "Epoch [69/100], Training Loss: 0.0408\n",
      "Epoch [70/100], Training Loss: 0.0402\n",
      "Epoch [71/100], Training Loss: 0.0446\n",
      "Epoch [72/100], Training Loss: 0.0386\n",
      "Epoch [73/100], Training Loss: 0.0380\n",
      "Epoch [74/100], Training Loss: 0.0387\n",
      "Epoch [75/100], Training Loss: 0.0430\n",
      "Epoch [76/100], Training Loss: 0.0471\n",
      "Epoch [77/100], Training Loss: 0.0395\n",
      "Epoch [78/100], Training Loss: 0.0457\n",
      "Epoch [79/100], Training Loss: 0.0405\n",
      "Epoch [80/100], Training Loss: 0.0409\n",
      "Epoch [81/100], Training Loss: 0.0394\n",
      "Epoch [82/100], Training Loss: 0.0385\n",
      "Epoch [83/100], Training Loss: 0.0421\n",
      "Epoch [84/100], Training Loss: 0.0402\n",
      "Epoch [85/100], Training Loss: 0.0395\n",
      "Epoch [86/100], Training Loss: 0.0399\n",
      "Epoch [87/100], Training Loss: 0.0370\n",
      "Epoch [88/100], Training Loss: 0.0440\n",
      "Epoch [89/100], Training Loss: 0.0380\n",
      "Epoch [90/100], Training Loss: 0.0373\n",
      "Epoch [91/100], Training Loss: 0.0367\n",
      "Epoch [92/100], Training Loss: 0.0352\n",
      "Epoch [93/100], Training Loss: 0.0373\n",
      "Epoch [94/100], Training Loss: 0.0376\n",
      "Epoch [95/100], Training Loss: 0.0368\n",
      "Epoch [96/100], Training Loss: 0.0377\n",
      "Epoch [97/100], Training Loss: 0.0355\n",
      "Epoch [98/100], Training Loss: 0.0348\n",
      "Epoch [99/100], Training Loss: 0.0380\n",
      "Epoch [100/100], Training Loss: 0.0371\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_dataloader:  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_loss:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), '../models/nbamodel.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing neural network on testing dataset\n",
    "\n",
    "Evaluate performance on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0399\n",
      "Accuracy: 98.51%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:  \n",
    "        outputs = model(inputs)\n",
    "        true_labels.append(labels.cpu().numpy())\n",
    "        pred_labels.append(outputs.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predicted_classes = (outputs >= 0.7).float()  \n",
    "        correct_predictions += (predicted_classes == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "true_labels = np.concatenate(true_labels)\n",
    "pred_labels = np.concatenate(pred_labels)\n",
    "\n",
    "\n",
    "average_test_loss = test_loss / len(test_dataloader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for Performance\n",
    "\n",
    "We'll use a confusion matrix to visualize performance. In this case, the order of the confusion matrix is TP, FP, FN, TN.\n",
    "\n",
    "TP (True Positive): When prediction is 1 and the true output is 1. <br>\n",
    "FP (False Positive): When prediction is 1 and the true output is 0. <br>\n",
    "TN (True Negative): When prediction is 0 and the true output is 0. <br>\n",
    "FN (False Negative): When prediction is 0 and the true output is 1. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19   4]\n",
      " [  1 311]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "threshold = 0.7\n",
    "\n",
    "pred_labels = (pred_labels >= threshold).astype(int)\n",
    "\n",
    "conf_mtx = confusion_matrix(true_labels, pred_labels, labels = [1,0])\n",
    "print(conf_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGdCAYAAACGtNCDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmF0lEQVR4nO3de3RU5dn38d8kMCPGEEEgA4KIIvoAiiUIhBcIQimxQpFnCW2hfY31FMFieapIPHAqLymoCTakWJRqBKsioFBOwYBFeQhRgyAQAmo5hsyQGDoTE5gJZN4/WqfZOxwSnDCh+/vJutfK7MO9r2kXyyvXde+9bZICAgAA+JeIcAcAAAAaF5IDAABgQHIAAAAMSA4AAIAByQEAADAgOQAAAAYkBwAAwIDkAAAAGJAcAAAAgybhDuA7J3yl4Q4BaHQckVeEOwSgUbqyyVUNe4EfXhu6uXKKQjfXJdJokgMAABoNmy3cEYQVbQUAAGBA5QAAADOL/+lMcgAAgJnF2wokBwAAmFk7N7B64QQAAJhROQAAwIy2AgAAMLB4Xd3iXx8AgMYjOTlZO3fulMfjkcfj0datW5WYmBjc73A4NH/+fJWWlqq8vFzLli1TmzZtDHN06NBBq1evVkVFhdxut+bOnavIyMh6xUFyAACAmc0WulEPR48e1ZQpUxQXF6devXpp06ZNWrlypbp27SpJSk9P14gRIzR69GglJCSoXbt2WrFiRfD8iIgIrVmzRna7Xf369dN9992npKQkzZw5s35fX1KgXmc0EB6fDNTG45OBs2vwxyf/pGPo5lp16Hud/s033+jJJ5/UsmXLVFJSorFjx2r58uWSpJtvvlmFhYXq27ev8vLylJiYqNWrV6tdu3Y6fvy4JOmRRx7RnDlz1Lp1a1VVVdXpmlQOAABoQHa7XdHR0YZht9sveF5ERIR++tOfKioqSrm5uYqLi5PdbldOTk7wmH379unQoUOKj4+XJMXHx2vXrl3BxECSsrOzFRMTo27dutU5ZpIDAADMImwhGykpKfJ6vYaRkpJyzkt3795d5eXl8vl8evnllzVq1Cjt3btXTqdTPp9PHo/HcLzb7ZbT6ZQkOZ1Oud3uWvu/21dX3K0AAIBZCO9kTE1NVVpammGbz+c75/H79u3T7bffrpiYGN17773KyspSQkJC6AKqA5IDAAAakN/vl9/vr/PxVVVV+vrrryVJ27dv1x133KHHH39c77zzjhwOh2JiYgzVg9jYWLlcLkmSy+VS7969DfPFxsYG99UVbQUAAMzCdLfC2URERMjhcCg/P19+v19DhgwJ7uvSpYs6duyo3NxcSVJubq5uvfVWtW7dOnjM0KFD5fF4VFBQUOdrUjkAAMAsTA9InD17ttatW6fDhw8rOjpaY8eO1aBBgzRs2DB5vV4tWrRIaWlpKisrk9frVUZGhrZu3aq8vDxJ0oYNG1RQUKDFixdr8uTJcjqdmjVrljIzM+tVvSA5AADALCI82UGbNm30xhtvqG3btvJ4PPriiy80bNiw4B0KkyZNUnV1tZYvXy6Hw6Hs7GyNHz8+eH51dbWGDx+uBQsWKDc3VxUVFcrKytLUqVPrFQfPOQAaMZ5zAJxdgz/nYPQNoZvr3b+Hbq5LhMoBAABm1n7vEskBAAC1WPytjNytAAAADKgcAABgFqYFiY0FyQEAAGbWzg1oKwAAACMqBwAAmFl8QSLJAQAAZtbODWgrAAAAIyoHAACYcbcCAAAwsHZuQHIAAEAtFl+QyJoDAABgQOUAAAAzi//pTHIAAIAZbQUAAIB/o3IAAICZtQsHJAcAANRCWwEAAODfqBwAAGBm8T+dSQ4AADCjrQAAAPBvVA4AADCzduGA5AAAgFp4KyMAADBgzQEAAMC/UTkAAMDM2oUDkgMAAMxsIWwrBEI206VDWwEAABhQOQAAwMTqlQOSAwAATCx+swJtBQAAYETlAAAAk4gQlg7OhGymS4fkAAAAk1CuObgc0VYAAAAGVA4AADCxeuWA5AAAABOSAwAAYGDx3IA1BwAAwIjKAQAAJrQVAACAgdWTA9oKAADAgMoBAAAmNlm7ckByAACACW0FAACAGqgcAABgYvHCAckBAABmoXwr4+WItgIAADAgOQAAwMRms4Vs1MeUKVP0ySefyOv1yu1267333lOXLl0Mx3z44YcKBAKGsWDBAsMxHTp00OrVq1VRUSG32625c+cqMjKyznHQVgAAwCRcdyskJCQoMzNTn376qZo0aaLZs2drw4YN6tq1qyorK4PHLVy4UFOnTg1+rrkvIiJCa9askcvlUr9+/dS2bVu98cYbqqqq0jPPPFOnOEgOAAAwCdeSg7vuusvwOSkpSSUlJYqLi9PHH38c3F5ZWSm3233WOX70ox+pa9eu+uEPf6jjx49r586deu655zRnzhxNnz5dVVVVF4yDtgIAAA3IbrcrOjraMOx2e53OjYmJkSSVlZUZto8bN04lJSXatWuXZs+erWbNmgX3xcfHa9euXTp+/HhwW3Z2tmJiYtStW7c6XZfkAAAAk1CuOUhJSZHX6zWMlJSUOsUwb948bdmyRXv27Alu/8tf/qJf/OIXuvPOO5Wamqpf/vKXWrJkSXC/0+msVVX47rPT6azT96etAACASSjXHKSmpiotLc2wzefzXfC8zMxMde/eXf379zdsf+WVV4K/7969W8XFxdq0aZNuuOEG/f3vfw9JzFQOAABoQH6/X+Xl5Ybh9/vPe05GRoaGDx+uO++8U0VFRec9Ni8vT5LUuXNnSZLL5VJsbKzhmO8+u1yuOsVMcgAAgEm4bmWU/pkYjBo1SoMHD9bBgwcvePztt98uSSouLpYk5ebm6tZbb1Xr1q2DxwwdOlQej0cFBQV1ioG2AgAAJuG6lTEzM1Njx47VyJEjVV5eHvyL3+Px6NSpU7rhhhs0duxYrV27Vt98841uu+02paena/Pmzdq1a5ckacOGDSooKNDixYs1efJkOZ1OzZo1S5mZmResWHzHJinQUF+yPk74SsMdAtDoOCKvCHcIQKN0ZZOrGnT+2BkDQjaXe9rHFz7oXwKBs/8nOSkpSVlZWWrfvr2WLFmi7t27KyoqSkeOHNF7772nWbNmqby8PHj8ddddpwULFmjQoEGqqKhQVlaWpkyZojNnztQpDpIDoBEjOQDOrqGTA+fM0CUHrql1Tw4aC9oKAACYhKut0FiwIBEAABhQOQAAwMTqlQOSAwAATCJIDgAAQE0Wzw1YcwAAAIyoHAAAYGL1NQdUDizq888+128fe1J3D/6J+tzaT5s3bjbs/6a0TDOfmaW7B/9EA++4U48nT9LhQ0fCFC3QOPz5ldd0e9eempv6fLhDQQOzhfDnckRyYFEnT57STV0668lnfltrXyAQ0OTHn1LR0SI9/4ffa/HS1+Vs69SvH5qok5UnwxAtEH67d+3RsqXL1eXmm8IdCtDgSA4sqt+AeCVPfESDhiTU2nfk0BHt/mKPnnruSXXt3lUdO3XUU889KZ/Ppw3rPghDtEB4VVZU6unJz2jqjOcU3bx5uMPBJRDOFy81BiQHqMXvr5Ik2R324LaIiAg1bWrXzu1fhCssIGxmz/q9BiT0V99+fcIdCi4RqycH9V6QeM011+hXv/qV4uPj5XQ6Jf3z/dBbt27V66+/rtJS3pFwubu+U0c528bqj/Ne1pSpk9XsymZ66423ddx9nP9/YTnr12arsKBQby5dHO5QgEumXpWDXr16af/+/Zo4caI8Ho8++ugjffTRR/J4PJo4caIKCwsVFxd3wXnsdruio6MNA41Hk6ZN9Pv0VB0+dERD+ycq4Y7Byv90u+L7xyvCRrEJ1uEqdmlu6vOaPXeWHA5HuMPBJWSzhW5cjupVOcjIyNC7776r5OTks+5/+eWXlZGRoX79+p13npSUFE2fPt2w7dSZSp06w2K3xuK/ut2iJcuy9G35t6qqqlKLli30q7EP6paut4Q7NOCSKdizV2XflOnn944Lbjtz5oy2f7Zd7/xlqT7ZsU2RkZFhjBAN5XJtB4RKvZKDHj16KCkp6Zz709PT9fnnn19wntTUVKWlpRm2HS49UJ9QcIlcFf3P16IePnREe/cU6uHHHgpzRMCl0ye+t5atXGrYNvWZ6erU6Xrd/2ASiQH+Y9UrOXC5XOrdu7f27dt31v29e/eW2+2+4Dx+v19+v78+l0aIVVZW6ujho8HPx4qKtb9wv5rHNJezrVMbszfp6pZXy+mM1Vdffq30OfM0cPBAFmTBUqKiotT5ps6Gbc2aNVPM1TG1tuM/C5WDenjhhRe0cOFCxcXFaePGjcFEIDY2VkOGDNFDDz2kJ554okECRWjt3VOo8b96LPh53vN/kCTd/ZMfa+r/e1alpaWa9/wfVPZNmVq1vkZ3jbhLDyTfH65wAeCSsnpyYJMUqM8JY8aM0aRJkxQXFxcsqZ05c0b5+flKS0vTu+++e1GBnPCxCh4wc0ReEe4QgEbpyiZXNej8XdKGhWyu/f+THbK5LpV638q4dOlSLV26VE2aNFGrVq0kSaWlpTp9+nTIgwMAAJfeRb946fTp03K5XKGMBQCARsHqbQXeyggAgInVkwOeaAMAAAyoHAAAYGL1ygHJAQAAJhbPDWgrAAAAIyoHAACY0FYAAAAGVk8OaCsAAAADKgcAAJhYvXJAcgAAgInFcwOSAwAAzKxeOWDNAQAAMKByAACAmcUrByQHAACY0FYAAACogcoBAAAmFi8ckBwAAGBGWwEAAKAGKgcAAJhYvXJAcgAAgInVkwPaCgAAwIDKAQAAJhYvHJAcAABgZvW2AskBAAAmVk8OWHMAAAAMqBwAAGBi9coByQEAACZWTw5oKwAAAAMqBwAAmFi8cEDlAAAAM5vNFrJRH1OmTNEnn3wir9crt9ut9957T126dDEc43A4NH/+fJWWlqq8vFzLli1TmzZtDMd06NBBq1evVkVFhdxut+bOnavIyMg6x0FyAABAI5GQkKDMzEz17dtXQ4cOVdOmTbVhwwZdeeWVwWPS09M1YsQIjR49WgkJCWrXrp1WrFgR3B8REaE1a9bIbrerX79+uu+++5SUlKSZM2fWOQ6bpEAov9jFOuErDXcIQKPjiLwi3CEAjdKVTa5q0Pn7v/nzkM21ZdxbF31uq1atVFJSooEDB+rjjz9W8+bNVVJSorFjx2r58uWSpJtvvlmFhYXq27ev8vLylJiYqNWrV6tdu3Y6fvy4JOmRRx7RnDlz1Lp1a1VVVV3wulQOAAAwCWVbwW63Kzo62jDsdnud4oiJiZEklZWVSZLi4uJkt9uVk5MTPGbfvn06dOiQ4uPjJUnx8fHatWtXMDGQpOzsbMXExKhbt251ui7JAQAADSglJUVer9cwUlJSLniezWbTvHnztGXLFu3Zs0eS5HQ65fP55PF4DMe63W45nc7gMW63u9b+7/bVBXcrAABgEsq7FVJTU5WWlmbY5vP5LnheZmamunfvrv79+4cumDoiOQAAwCSUD0Hy+/3y+/31OicjI0PDhw/XwIEDVVRUFNzucrnkcDgUExNjqB7ExsbK5XIFj+ndu7dhvtjY2OC+uqCtAACAmc0WulFPGRkZGjVqlAYPHqyDBw8a9uXn58vv92vIkCHBbV26dFHHjh2Vm5srScrNzdWtt96q1q1bB48ZOnSoPB6PCgoK6hQDlQMAABqJzMxMjR07ViNHjlR5eXnwL36Px6NTp07J6/Vq0aJFSktLU1lZmbxerzIyMrR161bl5eVJkjZs2KCCggItXrxYkydPltPp1KxZs5SZmVnnCgbJAQAAJuF6t8L48eMlSZs3bzZsT0pKUlZWliRp0qRJqq6u1vLly+VwOJSdnR08T5Kqq6s1fPhwLViwQLm5uaqoqFBWVpamTp1a5zh4zgHQiPGcA+DsGvo5B4Pf/WXI5to0enHI5rpUWHMAAAAMaCsAAGBi9Vc2kxwAAGASYfHkgLYCAAAwoHIAAIAJbQUAAGBg9bI6yQEAACasOQAAAKiBygEAACasOQAAAAa0FQAAAGqgcgAAgAltBQAAYGD1srrVvz8AADChcgAAgInVFySSHAAAYGL1NQe0FQAAgAGVAwAATGgrAAAAA2unBiQHAADUYvXKAWsOAACAAZUDAABMrF45IDkAAMCEWxkBAABqoHIAAIAJbQUAAGBg7dSAtgIAADChcgAAgAltBQAAYGD15IC2AgAAMKByAACAidWfc0ByAACAidXbCiQHAACYWDs1YM0BAAAwoXIAAIAJbQUAAGBg9eSAtgIAADCgcgAAgAm3MgIAAAOrl9Wt/v0BAIAJlQMAAExoKwAAAAPuVgAAAKiBygEAACZWrxyQHAAAYMKag0biishm4Q4BaHSaJXYJdwiAJUVY/NVLrDkAAAAGjaZyAABAY2H1tgKVAwAATCJstpCN+hgwYIBWrVqloqIiBQIBjRw50rD/tddeUyAQMIx169YZjmnRooWWLFkij8ejEydO6NVXX1VUVFT9vn+9jgYAAA0mKipKO3fu1IQJE855zLp16+R0OoPj5z//uWH/m2++qW7dumno0KEaPny4Bg4cqIULF9YrDtoKAACY2MK0IHH9+vVav379eY/x+Xxyu91n3XfLLbforrvuUq9evZSfny9J+vWvf621a9fqiSeeUHFxcZ3ioHIAAICJzWYL2Qi1QYMGye12q7CwUH/84x/VsmXL4L74+HidOHEimBhIUk5Ojqqrq9WnT586X4PKAQAADchut8vhcBi2+Xw++f3+es+1fv16rVixQgcOHNCNN96o2bNna926dYqPj1d1dbWcTqeOHz9uOOfMmTMqKyuT0+ms83WoHAAAYBLKBYkpKSnyer2GkZKSclFxvfPOO/rrX/+q3bt3a+XKlRo+fLh69+6tQYMGhfT7UzkAAMDEFsK/nVNTU5WWlmbY5vP5QjL3gQMHVFJSos6dO2vTpk1yuVxq06aN4ZjIyEi1bNlSLperzvOSHAAA0ID8fv9FtRDq4tprr9U111wTXGiYm5urFi1aqGfPntq+fbskafDgwYqIiFBeXl6d5yU5AADAJFwvXoqKilLnzp2Dnzt16qQePXqorKxMZWVlmjZtmpYvXy6Xy6Ubb7xRc+fO1VdffaXs7GxJUmFhodatW6dXXnlFycnJatq0qebPn6+33367zncqSKw5AACglnDdrdCrVy/t2LFDO3bskCSlp6drx44dmjlzps6cOaPbbrtNq1at0v79+7Vo0SLl5+drwIABhsrEuHHjVFhYqI0bN2rt2rXasmWLHn744XrFQeUAAACTcD3nYPPmzedNKBITEy84x4kTJzRu3LjvFQeVAwAAYEDlAAAAk3CtOWgsSA4AADDhrYwAAAA1UDkAAMAkwuJ/O5McAABgQlsBAACgBioHAACYWL1yQHIAAIBJRJgegtRY0FYAAAAGVA4AADChrQAAAAx4QiIAADAI14uXGgvWHAAAAAMqBwAAmETYrP23M8kBAAAmVl+QaO3UCAAA1ELlAAAAE6svSCQ5AADAxOq3MtJWAAAABlQOAAAwoa0AAAAMaCsAAADUQOUAAAATGw9BAgAANbHmAAAAGLDmAAAAoAYqBwAAmFj93QokBwAAmERYfM0BbQUAAGBA5QAAABPaCgAAwMDqzzmw9rcHAAC1UDkAAMDE6gsSSQ4AADCx+poD2goAAMCAygEAACa8WwEAABhYva1AcgAAgInVFySy5gAAABhQOQAAwMTqD0EiOQAAwMTqCxKtnRoBAIBaqBwAAGDC3QoAAMCAtgIAAEANVA4AADChrQAAAAx4CBIAAEANJAcAAJjYbLaQjfoYMGCAVq1apaKiIgUCAY0cObLWMTNmzNCxY8dUWVmpDz74QJ07dzbsb9GihZYsWSKPx6MTJ07o1VdfVVRUVL3iIDkAAMDEpoiQjfqIiorSzp07NWHChLPunzx5siZOnKjk5GT16dNHFRUVys7OlsPhCB7z5ptvqlu3bho6dKiGDx+ugQMHauHChfX8/lKgXmc0kJOnK8IdAtDoNEvsEu4QgMYpp6hBp1958N2QzTXy+tEXdV4gENA999yjlStXBrcdO3ZML774ol588UVJUvPmzeV2u5WUlKR33nlHt9xyi/bu3atevXopPz9fkjRs2DCtXbtW7du3V3FxcZ2uTeUAAIAGZLfbFR0dbRh2u73e83Tq1Elt27ZVTk5OcJvX61VeXp7i4+MlSfHx8Tpx4kQwMZCknJwcVVdXq0+fPnW+FskBAAAmthD+pKSkyOv1GkZKSkq9Y3I6nZIkt9tt2O52u4P7nE6njh8/bth/5swZlZWVBY+pC25lBADAJCKEzzlITU1VWlqaYZvP5wvZ/A2B5AAAgAbk9/vl9/u/9zwul0uSFBsbG/z9u887duwIHtOmTRvDeZGRkWrZsqXhnAuhrQAAgEko2wqhcuDAARUXF2vIkCHBbdHR0erTp49yc3MlSbm5uWrRooV69uwZPGbw4MGKiIhQXl5ena9F5QAAAJNwPT45KirK8NyCTp06qUePHiorK9ORI0c0b948Pfvss/ryyy914MAB/e53v9OxY8f0/vvvS5IKCwu1bt06vfLKK0pOTlbTpk01f/58vf3223W+U0EiOQAAoNHo1auX/va3vwU/p6enS5Jef/113X///Zo7d66ioqK0cOFCXX311dqyZYsSExMNaxjGjRun+fPna+PGjaqurtby5cs1ceLEesXBcw6ARoznHADn0MDPOVh3eOWFD6qju66r/ZTDxo7KAQAAJlZ/KyMLEgEAgAGVAwAATKz+ymaSAwAATKzeViA5AADAJJTPJ7gcseYAAAAYUDkAAMCEtgIAADCwWbywbu1vDwAAaqFyAACASShf2Xw5IjkAAMCEuxUAAABqoHIAAICJ1e9WoHIASVL+Z/n69fjH9cOEoerR9QfalPNhuEMCzit5+C+1808fyPP+Xnne36utL61U4h13nvP4rh27aNnUhTqwOFeBD47q8VEPXJI47x14t/Yu+ptOrvlKXyzM0V29Bwf3NYlsot8/+LS+WJijb1ftV9Hbnylr8jy1vSb2ksSGc7OF8OdyRHIASdLJypO6+eYuSnkuJdyhAHVytLRYUxalKm7Cj9Vrwo+1acf/auWMRera8eyvub7S0Ux/Lz6sKYtSVfyNOyQxJNwWrwOLc8+5P75rnN56OlOL1r+tHzyaqPf/d73en/6qul1/czCmnp2763dL5qnn+ET994yHdXP7G7Vq5p9DEh9wsWgrQJLUf2B/9R/YP9xhAHW2eluO4fOzr83Vo8P/r/r+V08VHNpf6/jP9u/UZ/t3SpJ+/8DZk2CbzaanfjpeD/94nJwt22j/0b/rd2++pOUfr7moGB8f9YDWf/o3vfDuy5KkqVkvaGjcQD02MkmPvpQib2W5fjRlrOGcx+Y/q08z16hD63Y6UnLsoq6L78/qbQWSAwCXvYiICI0eOFxRVzRTbkH+Rc+T8vPH9Ish/63kP6Toy6MHNPC2Ploy5SWVeL7RR19sq/d88V3jlLZsoWFb9mebdU+/Yec8JyYqWtXV1fpHhbfe10PoRFi8sE5yAOCy1f36W5T7h5W6wu7QtycrNGrGQ9p7+MuLmsve1K6nf/Zr/fCpn2nb3u2SpAOuw+rfvbceufsXF5UcOFu0lvsfpYZt7hMlcrZsfdbjHU0dmvPg03rrw5Uqr/y2/l8CIUPlIMTat2+vGTNm6IEHzr3Yx263y+FwhPrSACxm39GvdXvyMMVEReveAXcr68l0Jfz23otKEDq3u15Rza7UB3PeMmy3N2mqz7/aE/xcvmpf8PfIiEg5mtoN25ZsXKFHX6r/2p0mkU209LkFstlsevQPrP1BeIU8OWjZsqXuu+++8yYHKSkpmj59umHb6eoqnQ5UhTocAP/Bqk5X6etjByVJ27/cpTtu7qHHRz2g5Jem1Huuq5pFSZLufvY+FZW6DPt8Vb7g77cn/7sl0OeWH2jOg09r0BOjg9u8leXB310nShR7dSvDXLEtWstVVmLY1iSyiZY++7I6tmmvwU+OoWrQCFyudxmESr2TgxEjRpx3/w033HDBOVJTU5WWlmbYdvyE6xxHA0DdRNgi5LDbL+rcgkP7dcp/Ste1ufa8LYTvkhFJat+qrU6fOW3YVlNuQb6G/KC/XnpvUXDb0J4DlLv33+sivksMbrr2et355BiVlf/jouJHaNFWqKf3339fgUDgvP/DBQKB887h9/vl9/vre2k0oMqKSh0+fCT4uaioSIV79ykmprnatmsbxsiAs5v9qyla9+mHOny8SNHNrtLYwfdoUI94DUsZJ0nKmjxPRaUuPf3n30uSmjZpqq4db5Ik2Zs21bWt2qrHjV317clKfX3soL49WaEX3v2T0pOnKcJm05bdnyomKlr/p9sd8laW640PltU7xpfeW6TNLy7T/9z7sNbkbdTPBo1Ury636eF5T0n6Z2KwbOqf1LPzrRr+3H2KjIhUbIt/rkcoK/+Hqk5TTUV41Ds5KC4u1vjx47Vq1aqz7u/Ro4fy8y9+tTDCY8+eAj2Y9FDw8wtzXpQk/eSeEfrd7JnhCgs4pzZXt9Ibk+epbcs28lSU64sDezUsZZxytn8sSbquzbWqDlQHj293Tax2vLwh+PnJMcl6ckyy/rYzV3f+qy3w3OvPq8RTppSfPaYb2l6nf3zr1favdmv2WxkXFWNuQb7Gpj6mWUmTNfv+p/Rl0QHdM/1B7Tn4zzUK17ZyauS/7lzY+acPDOcO+u1obf7i3M9QQMOyelvBJun8f+abrFy5Ujt27NC0adPOuv+2227T559/rsjIyHoFcvJ0Rb2OB6ygWeLZH+gDWF5OUYNO/+nxLSGb6442l98zZOpdOXj++ecVFRV1zv1fffWV7rzz3I8wBQAAjVu9k4MtW86fTVVWVuqjjz666IAAAAg7FiQCAICarL7mwNrPhwQAALVQOQAAwITnHAAAAAOrtxVIDgAAMLF6csCaAwAAYEDlAAAAE9YcAAAAA9oKAAAANVA5AADAxOqVA5IDAABMrL7mgLYCAAAwoHIAAIAJbQUAAGBAWwEAAKAGKgcAAJjQVgAAAAYkBwAAwIA1BwAAADVQOQAAwIS2AgAAMLB6ckBbAQAAGFA5AADAhAWJAADAxBbCUXfTpk1TIBAwjL179wb3OxwOzZ8/X6WlpSovL9eyZcvUpk2b7/dVz4LkAACARmT37t1yOp3B0b9//+C+9PR0jRgxQqNHj1ZCQoLatWunFStWhDwG2goAAJiEs61w+vRpud3uWtubN2+uBx54QGPHjtWHH34oSbr//vtVWFioPn36KC8vL2QxUDkAAMDEFsIfu92u6Ohow7Db7ee89k033aSioiJ9/fXXWrJkiTp06CBJiouLk91uV05OTvDYffv26dChQ4qPjw/p9yc5AACgAaWkpMjr9RpGSkrKWY/Ny8tTUlKSEhMT9eijj6pTp076+OOPddVVV8npdMrn88nj8RjOcbvdcjqdIY2ZtgIAACahfM5Bamqq0tLSDNt8Pt9Zj12/fn3w9127dikvL0+HDh3SmDFjdPLkyZDFdCEkBwAAmIRyzYHf75ff77+ocz0ej/bv36/OnTvrgw8+kMPhUExMjKF6EBsbK5fLFapwJdFWAACgllCuOfg+oqKidOONN6q4uFj5+fny+/0aMmRIcH+XLl3UsWNH5ebmft+vbEDlAACARuL555/XX//6Vx06dEjt2rXTjBkzdObMGb311lvyer1atGiR0tLSVFZWJq/Xq4yMDG3dujWkdypIJAcAANQSrncrtG/fXm+99ZauueYalZSUaMuWLerbt69KS0slSZMmTVJ1dbWWL18uh8Oh7OxsjR8/PuRx2CQFQj7rRTh5uiLcIQCNTrPELuEOAWiccooadPrD334dsrmuu+rGkM11qbDmAAAAGNBWAADAxOqvbCY5AADAhLcyAgAA1EDlAAAAE9oKAADAxNrJAW0FAABgQOUAAAATa9cNSA4AAKjF6ncrkBwAAFCLtZMD1hwAAAADKgcAAJhYu25AcgAAwFlYOz2grQAAAAyoHAAAYGL1uxWoHAAAAAOSAwAAYEBbAQAAE168BAAADKyeHNBWAAAABiQHAADAgLYCAAAm3MoIAABQA8kBAAAwoK0AAICJ1e9WIDkAAKAWaycHtBUAAIABlQMAAEysXTcgOQAAoBZuZQQAAKiBygEAALVYu3JAcgAAgIm1UwPaCgAAwITKAQAAtVi7dkByAACACXcrAAAA1EByAAAADGgrAABgwouXAACAibWTA9oKAADAgMoBAAAm1q4bkBwAAFALtzICAADUQOUAAIBarF05IDkAAMDE2qkBbQUAAGBC5QAAgFqsXTsgOQAAwIS7FQAAAGogOQAAAAa0FQAAMLH6i5ckKcBgfDfsdntg2rRpAbvdHvZYGIzGMvh3wbDasP3rF0CSFB0dLa/Xq+bNm6u8vDzc4QCNAv8uYDWsOQAAAAYkBwAAwIDkAAAAGJAcwMDn82n69Ony+XzhDgVoNPh3AathQSIAADCgcgAAAAxIDgAAgAHJAQAAMCA5AAAABiQHCBo/frwOHDigkydPatu2bbrjjjvCHRIQVgMGDNCqVatUVFSkQCCgkSNHhjsk4JIgOYAkacyYMUpLS9OMGTPUs2dP7dy5U9nZ2WrdunW4QwPCJioqSjt37tSECRPCHQpwyYX9BQ+M8I9t27YFMjIygp9tNlvg6NGjgaeeeirssTEYjWEEAoHAyJEjwx4Hg3EpBpUDqGnTpoqLi1NOTk5wWyAQUE5OjuLj48MYGQAgHEgOoFatWqlJkyZyu92G7W63W06nM0xRAQDCheQAAAAYkBxApaWlOn36tGJjYw3bY2Nj5XK5whQVACBcSA6gqqoq5efna8iQIcFtNptNQ4YMUW5ubhgjAwCEQ5NwB4DGIS0tTVlZWfrss8/0ySef6De/+Y2ioqL02muvhTs0IGyioqLUuXPn4OdOnTqpR48eKisr05EjR8IYGdDwwn7LBKNxjAkTJgQOHjwYOHXqVGDbtm2B3r17hz0mBiOcIyEhIXA2r732WthjYzAacvDKZgAAYMCaAwAAYEByAAAADEgOAACAAckBAAAwIDkAAAAGJAcAAMCA5AAAABiQHAAAAAOSAwAAYEByAAAADEgOAACAAckBAAAw+P+y70B20O3XIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "plt.xlabel(\"\")\n",
    "sns.heatmap(conf_mtx, annot = True, cmap = \"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1 311 4\n"
     ]
    }
   ],
   "source": [
    "TP = conf_mtx[0][0]\n",
    "FP = conf_mtx[1][0]\n",
    "TN = conf_mtx[1][1]\n",
    "FN = conf_mtx[0][1]\n",
    "\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Precision is calculated as follows: $$ \\frac{TP}{(TP + FP)} $$\n",
    "\n",
    "Recall is calculated as follows: $$ \\frac{TP}{(TP + FN)} $$\n",
    "\n",
    "f1Score is calculated as follows: $$ \\frac{Precision * Recall}{(Precision + Recall)} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.95\n",
      "Recall: 0.8260869565217391\n",
      "f1score: 0.44186046511627913\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1score = (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'f1score: {f1score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47e47cda05e9886a0f1932160b1f70f95aa1d71424dff224d867803480b36f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
